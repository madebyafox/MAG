---
title: "MAG — S2 WRANGLING EDA"
author: "ANONYMIZED"
date: "2024-02-04"
output:
  html_document:
    theme: flatly
    code_folding: hide
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 5
  pdf_document:
    toc: yes
    toc_depth: '4'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(tidyverse) #all the things
library(magrittr) #special pipes like %<>%
library(summarytools) #data quality
library(jtools) #Social Science regression utilities
library(lubridate) #dealing with dates

#VIZ
library(kableExtra) #printing tables
library(ggformula) #regression syntax viz
# library(vcd) #mosaic plots
# library(vcdExtra) #mosaic plot helpers
library(ggstatsplot) #dummies
library(GGally) #extends ggplot for EDA 

#MODELLING
library(easystats) #modelling helpers
library(see)
library(sjPlot)
library(lme4)
library(lmerTest) #for CIs in glmer

options(readr.show_col_types = FALSE) #don't show coltypes on read_csv

#POWER ANALYSIS & SIMULATION
library(pwr)
library(simr)

#ARF ONLY — MANUAL RUN
# setwd("~/Code/IXN-Characterizing_Interaction/IXN-D_Characterizing_Interaction/ANALYSIS")

```

Data were exported from TODO to file `tbd` which wasTODO  `TODO` by TODO.


```{r WRANGLING, message=FALSE, warning=FALSE}

#df_raw will always be the unaltered version of imported data
# 1 row per subject 
df_raw <- read_csv("data/CLEAN_v2_testdata.csv", col_names = TRUE)

#### MASTER WIDE FORMAT DATA FRAME ##########################
# 1 row per subject, each trial is a set of columns prefixed by the stimulus number eg. 1_Q..., 10_Q....
#DROP first two rows —— qualtrics specs 
df_data <- df_raw[-c(1:2),] %>%  select(
#DROP junk columns
  -EndDate, -IPAddress,-Progress,-RecordedDate,
  -RecipientLastName, -RecipientFirstName, -RecordedDate, -RecipientEmail,
  -ExternalReference, -LocationLatitude, -LocationLongitude, 
  -UserLanguage, -CONSENT, -ELIGIBILITY, -PROLIFIC_PID,
  -Q_RecaptchaScore, 
  -contains("Q1") #junk end columns
) %>% rename (  #RENAME COLUMNS
  ID_QUALTRICS = ResponseId,
  duration_sec = `Duration (in seconds)`,
  BROWSER_OS = `BROWSER_Operating System`,
  PLATFORM = Q_PLATFORM
) %>% mutate(
  StartDate = mdy_hm(StartDate),
  duration_sec = as.numeric(duration_sec) #weird boolean data should only be for the test generator
)

## TODO HANDLE DEMOGRAPHICS AND PARTICIPANT POOL LOGISTICS 
##temporary adding simulated sample data to approximate pool 
x <- sample(x = c("POP1", "POP2"),
       prob = c(.5, .5), # Make the coin biased for Heads
       size = nrow(df_data),
       replace = TRUE)
df_data$POOL <- x


#SET CERTAIN COLUMNS AS VECTORS
#columns that should be vectors
vecs <- c("ID_QUALTRICS","ID_PROLIFIC","Status",
          "Finished", "DistributionChannel", "PLATFORM", 
          "BROWSER_Browser", "BROWSER_Version", "BROWSER_OS", "BROWSER_Resolution",
          "POOL")


#super duper special pipe that is like an apply?
# https://stackoverflow.com/questions/33180058/coerce-multiple-columns-to-factors-at-once
df_data %<>% mutate_each_(funs(factor(.)),vecs)


#### SUBJECT DATA FRAME ##########################
# 1 row per subject 
#TODO eventually combine with demographic data 
df_subjects <- df_data %>% select(
  ID_QUALTRICS, ID_PROLIFIC, 
  duration_sec, DistributionChannel, 
  StartDate, Status, Finished, PLATFORM, POOL,
  contains("BROWSER")
) 

## CHECK FOR SURVEY COMPLETION
print("Number of subjects who didn't finish survey?")
sum(df_subjects$Finished == FALSE)
#this _should_ always be TRUE because we configured Qualtrics to not save unless the survey is finished 
n_subjects <- nrow(df_subjects)



#TODO FOR REAL DATA NEED TO HANDLE STATUS COLUMN to make sure not test data is in there 


#### RESPONSE DATA FRAME (WIDE) ##########################
# 1 row per subject, only response and relevant participant data 
df_responses <- df_data %>% select(
  ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("_")
)

#### CONSTRUCTING RESPONSES FRAME (LONG) ##########################
#SUPER FLIPPIN HACKY JANKS BC QUALTRICS IS THE WORST ---- COULD refactor this using functions 

#get the data for the first graph
graph_1 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("1_")) %>% 
  mutate(
    graph = "s1",
    in_loop = `1_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^1_","")) #strip the 1_ prefix

#get the data for the second graph
graph_2 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("2_")) %>% 
  mutate(
    graph = "s2",
    in_loop = `2_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^2_","")) #strip the 2_ prefix


#get the data for the third graph
graph_3 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("3_")) %>% 
  mutate(
    graph = "s3",
    in_loop = `3_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^3_","")) #strip the 3_ prefix


#get the data for the fourth graph
graph_4 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("4_")) %>% 
  mutate(
    graph = "s4",
    in_loop = `4_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^4_","")) #strip the 4_ prefix


#get the data for the fifth graph
graph_5 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("5_")) %>% 
  mutate(
    graph = "s5",
    in_loop = `5_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^5_","")) #strip the 5_ prefix


#get the data for the sixth graph
graph_6 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("6_")) %>% 
  mutate(
    graph = "s6",
    in_loop = `6_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^6_","")) #strip the 6_ prefix


#get the data for the seventh graph
graph_7 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("7_")) %>% 
  mutate(
    graph = "s7",
    in_loop = `7_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^7_","")) #strip the 7_ prefix

#get the data for the eigth graph
graph_8 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("8_")) %>% 
  mutate(
    graph = "s8",
    in_loop = `8_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^8_","")) #strip the 8_ prefix

#get the data for the ninth graph
graph_9 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("9_")) %>% 
  mutate(
    graph = "s9",
    in_loop = `9_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^9_","")) #strip the 9_ prefix

#get the data for the tenth graph
graph_10 <- df_responses %>% 
  select(ID_QUALTRICS, PLATFORM, POOL, duration_sec, contains("10_")) %>% 
  mutate(
    graph = "s10",
    in_loop = `10_loop-number`
  ) %>% rename_all(~stringr::str_replace(.,"^10_","")) #strip the 10_ prefix


#nrow(df_responses) should be nrow(df_data) X 10, if each participant saw 10 graphs
df_responses <- bind_rows(graph_1 ,graph_2, graph_3, graph_4, graph_5, 
                       graph_6, graph_7, graph_8, graph_9, graph_10)


#get rid of trailing _1
df_responses <- df_responses %>% 
  rename_all(~stringr::str_replace(.,"_65","")) %>%  #strip the _65 suffix
  rename_all(~stringr::str_replace(.,"_1","")) %>%   #strip the _1 suffix
  select(-`loop-number`, -contains(c("_First Click", "_Last Click"))) %>% 
  rename(
    Q_MAKER_CHAR_LATENCY_sec    =  'Q_MAKER_CHAR_LATENCY_Page Submit',
    Q_MAKER_ATT_LATENCY_sec     =  'Q_MAKER_ATT_LATENCY_Page Submit',
    Q_CONCLUSION_LATENCY_sec    =  'Q_CONCLUSION_LATENCY_Page Submit',
    Q_MAKER_CHAR_LATENCY_clicks =  'Q_MAKER_CHAR_LATENCY_Click Count',
    Q_MAKER_ATT_LATENCY_clicks =  'Q_MAKER_ATT_LATENCY_Click Count',
    Q_CONCLUSION_LATENCY_clicks =  'Q_CONCLUSION_LATENCY_Click Count'
  )

x <- colnames(df_responses) 
#columns that should be vectors
vecs <- c( "Q_ENCOUNTER","comment", "share", "share_comment", "research","unfollow", "NOTHING", 
           "Q_MAKER_ID", "Q_INSTRUMENT_ID", "graph", "in_loop", "POOL")
#columns that should be doubles
nums <- c( "Q_MAKER_ID_CONF", "Q_MAKER_AGE", "Q_MAKER_GENDER", "Q_MAKER_DESIGN", 
           "Q_MAKER_DATA", "Q_MAKER_SPECTRUM", "Q_MAKER_EXPERT", 
          "Q_MAKER_BIAS", "Q_MAKER_ALIGNMENT", "Q_MAKER_COMPETENCE", "Q_MAKER_TRUST",
          "Q_MAKER_POLITE", "Q_MAKER_CARE", "Q_INSTRUMENT_CONF", "Q_CHART_INFORM",
          "Q_CHART_LIKE", "Q_CHART_EFFECTIVE", "Q_CHART_TRUST", "Q_CHART_AESTHETIC", 
          "Q_CONCLUSION_LATENCY_sec", "Q_MAKER_CHAR_LATENCY_sec", "Q_MAKER_ATT_LATENCY_sec", 
          "Q_CONCLUSION_LATENCY_clicks", "Q_MAKER_CHAR_LATENCY_clicks", "Q_MAKER_ATT_LATENCY_clicks")
explains <- c("Q_BEHAVIOR_EXPLAIN", "Q_MAKER_ID_DETAIL",  "Q_MAKER_CHAR_EXPLAIN","Q_MAKER_ATT_EXPLAIN", "Q_INSTRUMENT_DETAIL", "Q_CONCLUSION_EXPLAIN")


#super duper special pipe that is like an apply?
# https://stackoverflow.com/questions/33180058/coerce-multiple-columns-to-factors-at-once
df_responses %<>% mutate_each_(funs(factor(.)),vecs)
df_responses %<>% mutate_each_(funs(as.numeric(.)),nums)


#df just for free response variables 
df_freeresponse <- df_responses %>% select(ID_QUALTRICS, PLATFORM, POOL, Q_BEHAVIOR_EXPLAIN, Q_MAKER_ID,  Q_MAKER_ID_CONF, Q_MAKER_ID_DETAIL, Q_MAKER_CHAR_EXPLAIN, Q_MAKER_ATT_EXPLAIN, Q_INSTRUMENT_ID, Q_INSTRUMENT_CONF, Q_INSTRUMENT_DETAIL, Q_CONCLUSION_EXPLAIN)

#remove free responses from df_graphs and calc time in mins
df_responses <- df_responses %>% select(-one_of(explains)) %>% 
  mutate(duration_min = duration_sec/60)


#REMOVE TEMP DATAFRAMES
rm(graph_1, graph_2, graph_3, graph_4, graph_5, graph_6, graph_7, graph_8, graph_9, graph_10)
rm(explains,nums,vecs,x)


#SANITY CHECK 
```

`df_raw` should contain 2 more rows than `df_data` (qualtrics config)
`df_data` and `df_subjects` are one row per participant 
`df_responses` and `df_freeresponse` are one row per participant trial (i.e. participant X t number of trials)

# DATA PROFILE

```{r PROFILER, results="asis" }

df_responses%>% summarytools::dfSummary(
             varnumbers = FALSE,
             plain.ascii  = FALSE,
             graph.magnif = 0.75,
             style        = "grid",
             tmp.img.dir  = "temp",
             missing.col = FALSE, 
             method = "render"
)

```


## TODO Handle Attention Checks
## TODO Handle Behaviour Yes/Nos
## TODO Handle Instrument Multi-select



# SIMULUATE DATA

- Participants from two demographic pools (data-collar, blue-collar) will be recruited
- [NO BETWEEN-SUBJECTS MANIPULATION]
- Each participant will be measured 4 times (2 news graphs, 2 art graphs)


Simulate a dataset of 50 participants each looking at 6 graphs, two each of 3 types
n = participants = 50
v = vis = 6
g = genre = 3 
```{r}

# library(lme4)
# library(lmerTest)
library(afex) # for p values
library(simr)
simrOptions(progress=FALSE)

########## EXAMPLE ############
#https://humburg.github.io/Power-Analysis/simr_power_analysis.html
#10 children from 5 different classes (50 kids) will be recruited and assigned to an intervention or control group and measured 3 times. 

#VALID VALUES
subj <- factor(1:10)
class_id <- letters[1:5]
time <- 0:2
group <- c("control", "intervention")

#SAMPLE VECTORS
subj_full <- rep(subj, 15)
class_full <- rep(rep(class_id, each=10), 3)
time_full <- rep(time, each=50)
group_full <- rep(rep(group, each=5), 15)

#DATAFRAME
sim <- data.frame(id=subj_full, class=class_full, treat=group_full, time=factor(time_full))

# For the purpose of this example parameter values were chosen arbitrarily but should be based on literature or experience as much as possible for real studies.

## Intercept and slopes for intervention, time1, time2, intervention:time1, intervention:time2
fixed <- c(5, 0, 0.1, 0.2, 1, 0.9)

## Random intercepts for participants clustered by class
rand <- list(0.5, 0.1)

## residual variance
res <- 2

###### model definition
# y ~ treatment + time + treatment*time + (1|class/id) + e

##### CREATE MODEL #######
model <- makeLmer(y ~ treat*time + (1|class/id), fixef=fixed, VarCorr=rand, sigma=res, data=sim)

summary(model)
anova(model)

###POWER ANALYSIS
# Once you have a fitted lmer model, whether it was fitted to real data or created from scratch, you can use that to simulate new data and assess the required sample size.

# The powerSim function allows us to estimate the power to detect a specific effect in the model. Here we are interested in the effect of the intervention. Since the treatment variable is part of an interaction we will assess its effect by comparing the model specified above to the the alternative model that doesn’t include a treatment variable. We can provide this model alternative via the fcompare function. This allows us to only specify the fixed effects in the alternative model. All random effects will be assumed to be the same as in the original model.



sim_treat <- powerSim(model, nsim=100, test = fcompare(y~time))
sim_treat
#see that we have relatively little power



### CHANGING EFFECT SIZE 
# We can adjust the effect size to suit the analysis, e.g. to compute power for an effect size that is smaller than the one observed in a pilot study, or to study power for a range of effect sizes.


model_large <- model
fixef(model_large)['treatintervention:time1'] <- 2

sim_treat_large <- powerSim(model_large, nsim=100, test = fcompare(y~time))
sim_treat_large
#see that we have much higher power




### CHANGING NUMBER OF CLASSES [WHAT does class correspond to?]
# To study the effect an increase in sample size has on our ability to detect the effect of interest we can increase the number of levels for one of the factors in our model. This can be achieved with the extend function. For example, we could increase the number of classes from 5 to 20.

model_ext_class <- extend(model, along="class", n=20)
summary(model_ext_class)


##VISUALIZE POWER CURVE
# We can visualise the effect that varying the number of classes has on the power to detect the intervention effect by asking simr to plot a power curve.

#power analysis for increasing classes  
sim_treat_class <- powerSim(model_ext_class, nsim=100, test = fcompare(y~time))
sim_treat_class
#AGAIN lots of power 

#now plot a power curve 
#CAREFUL THIS ONE IS LONG
p_curve_treat <- powerCurve(model_ext_class, test=fcompare(y~time), along="class")
plot(p_curve_treat)

```





For the sake of this tutorial, let’s assume researchers are planning to investigate the effect of native language (English vs. non-English) in a lexical decision task where participants are asked to decide if displayed letter strings form an English word or are non-words. Additionally, they are interested if word frequency (i.e. how often a word appears in the English language) has an impact on the effect of native language.


GLMER RQ? Are native English speakers more accurate in the lexical decision task?
# formula for artificial model
formula <- Accuracy ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)

LMER RQ? Are native English speakers faster in categorizing words vs. non-words?

# formula for artificial model
formula <- Latency ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)


```{r}
#see also 
# https://lkumle.github.io/power_notebooks/Scenario3_notebook.html


#CREATE SIMULATED DATA 
# 1. create subject IDs  -> let's start with 20 subjects
subject_ID <- (1:20)

# 2. create stimuli IDS -> every subject should read 100 words
stimuli_ID <- (1:100)

# 3. combine subject IDs and stimui IDs
artificial_data <- expand.grid(Subject = subject_ID, Word = stimuli_ID)

##FIXED EFFECTS 


# Next, we need to include the fixed effects native language and frequency. Let’s start with native language, which we agreed to have two levels (English vs. Non-English). We will code those two levels using the labels -0.5 for English speakers and 0.5 for Non-English speakers and will keep both groups balanced (i.e. including as many English speakers as Non-English speakers in our sample). Note, that unbalanced groups lead to reduced power (Kumle, Vo & Draschkow, 2021) and should therefore be considered when planning sample size and recruitment.


# 1. create vector including identifier for native language, coded as -0.5 and +0.5 [not sure why]
native_language <- c(rep(-0.5, 1000), rep(0.5, 1000))

# --> we will have 10 subjects in every group, each of whom reads 100 words
# --> the vector needs to contain 1000 "-0.5" and 1000 "0.5" entries

# 2. add vector to data set
artificial_data["NativeLanguage"] <- native_language


# In a next step, we will generate frequency ratings for our second fixed effect. Since they will heavily influence our data structure, we need to be able to justify which frequency ratings we use. Ideally, we would already have actual frequency ratings on hand or know the frequencies’ distribution from which we can sample. In this example, we choose to sample from a normal distribution with a mean of 5 and standard deviation of 1. Afterwards, we will center the variable.


#  1. generate frequency ratings
frequency_ratings <- rnorm(100, mean = 5, sd = 1) # draw 100 frequency rating (one for every word)

# 2. add to data frame
artificial_data["Frequency"] <- rep(frequency_ratings, 20) # multiply by 20 (for every subject)
CenteredFrequency <- scale(artificial_data$Frequency, scale = F)
artificial_data <- cbind(artificial_data, CenteredFrequency)

glimpse(artificial_data)


#### POWER ANALYSIS 
# ------------------------------------------ #
# SPECIFY BETA COEFFICIENTS FOR FIXED EFFECTS
fixed_effects <-  c(-4.3, 0.35, -0.4, -0.32) # order follows the order in model summary and formula

# ------------------------------------------ #
# SET RANDOM INTERCEPT VARIANCE
random_variance <- list(1.04, 0.65)

# ------------------------------------------ #
# SET RESIDUAL STANDARD DEVIATION
sigma <- 0.26

##SIMULATE LMER 
# ------------------------------------------ #
# CREATE LMER
artificial_lmer <- makeLmer(formula = Speed ~ NativeLanguage * CenteredFrequency +
                                      (1 | Subject) + (1 | Word),
                           fixef = fixed_effects, VarCorr = random_variance, sigma = sigma,
                           data = artificial_data)

# lets have a look!
summary(artificial_lmer)



# ------------------------------------------ #
# POWER ANALYSIS WITH SIMR
power_simr <- powerSim(artificial_lmer, test= fixed("NativeLanguage"),  nsim=100)

# ------------------------------------------ #
# let's have a look:
print(power_simr)



#PRINT POWER CURVE 
p_curve_treat <- powerCurve(power_simr, test=fixed("NativeLanguage"), along="Subject")
plot(p_curve_treat)

```

```{r}
library(mixedpower)

# ------------------------------------------ #
# INFORMATION ABOUT MODEL USED FOR SIMULATION

model <- artificial_lmer # which model do we want to simulate power for?
data <- artificial_data # data used to fit the model
fixed_effects <- c("NativeLanguage", "CenteredFrequency") # all fixed effects specified in artificial_glmer
simvar <- "Subject" # which random variable do we want to vary in the simulation?

# ------------------------------------------ #
# SIMULATION PARAMETERS
steps <- c(20,60,100,140,180) # which sample sizes do we want to look at?
critical_value <- 2 # which t/z value do we want to use to test for significance?
n_sim <- 1000 # how many single simulations should be used to estimate power?

# ------------------------------------------ #
# INCLUDE SESOI SIMULATION
SESOI <-c(-4.3,  0.30 ,-0.34, -0.27) # specify SESOI (15% smaller betas)



# ------------------------------------------ #
# RUN SIMULATION WITH MIXEDPOWER
power <- mixedpower(model = model, data = data,
                       fixed_effects = c("NativeLanguage", "CenteredFrequency"),
                       simvar = "Subject", steps = c(20,60,100,140,180),
                       critical_value = 2, n_sim = 1000,
                       SESOI = c(-4.3,  0.30 ,-0.34, -0.27))


# ------------------------------------------ #
# LOOK AT RESULTS
power

saveRDS(power, file="mixedpower-simulation.RDS")
power <- readRDS(file="mixedpower-simulation.RDS")
# ------------------------------------------ #
# PLOT THE RESULTS
multiplotPower(power)




```


# AMY SIMULATION

```{r}
library(mixedpower)
#see also 
# https://lkumle.github.io/power_notebooks/Scenario3_notebook.html


#CREATE SIMULATED DATA 
# 1. create subject IDs  -> let's start with 20 subjects
n = 100
subject_ID <- (1:n)

# 2. create stimuli IDS -> every subject should read 4 words
t = 4
stimuli_ID <- (1:t)

# 3. combine subject IDs and stimui IDs
artificial_data <- expand.grid(Subject = subject_ID, Word = stimuli_ID)

##FIXED EFFECTS 

# 1. create vector including identifier for native language, coded as -0.5 and +0.5 [not sure why]
native_language <- c(rep(-0.5, n/2), rep(0.5, n/2))

# --> we will have 10 subjects in every group, each of whom reads 100 words
# --> the vector needs to contain 1000 "-0.5" and 1000 "0.5" entries

# 2. add vector to data set
artificial_data["NativeLanguage"] <- native_language


# In a next step, we will generate frequency ratings for our second fixed effect. Since they will heavily influence our data structure, we need to be able to justify which frequency ratings we use. Ideally, we would already have actual frequency ratings on hand or know the frequencies’ distribution from which we can sample. In this example, we choose to sample from a normal distribution with a mean of 5 and standard deviation of 1. Afterwards, we will center the variable.


#  1. generate frequency ratings
frequency_ratings <- rnorm(n*t, mean = 50, sd = 30) # draw 80 frequency rating (one for every graph)

# 2. add to data frame
artificial_data["Frequency"] <- frequency_ratings # multiply by 20 (for every subject)
# CenteredFrequency <- scale(artificial_data$Frequency, scale = F)
# artificial_data <- cbind(artificial_data, CenteredFrequency)

glimpse(artificial_data)


#### POWER ANALYSIS 
# ------------------------------------------ #
# SPECIFY BETA COEFFICIENTS FOR FIXED EFFECTS
fixed_effects <-  c(50, -20, 10, 5) # order follows the order in model summary and formula

# ------------------------------------------ #
# SET RANDOM INTERCEPT VARIANCE
random_variance <- list(10,20 )
  # list(1.04, 0.65)

# ------------------------------------------ #
# SET RESIDUAL STANDARD DEVIATION
sigma <- 2
  # 0.26

##SIMULATE LMER 
# ------------------------------------------ #
# CREATE LMER
artificial_lmer <- makeLmer(formula = Speed ~ NativeLanguage * Frequency +
                                      (1 | Subject) + (1 | Word),
                           fixef = fixed_effects, VarCorr = random_variance, sigma = sigma,
                           data = artificial_data)

# lets have a look!
summary(artificial_lmer)



# ------------------------------------------ #
# POWER ANALYSIS WITH SIMR
power_simr <- powerSim(artificial_lmer, test= fixed("NativeLanguage"),  nsim=100)

# ------------------------------------------ #
# let's have a look:
print(power_simr)



#PRINT POWER CURVE 
# THIS IS WHAT DIDN'T WANT TO RUN
# p_curve_treat <- powerCurve(power_simr, test=fixed("NativeLanguage"), along="Subject")
# plot(p_curve_treat)


# ------------------------------------------ #
# INFORMATION ABOUT MODEL USED FOR SIMULATION

model <- artificial_lmer # which model do we want to simulate power for?
data <- artificial_data # data used to fit the model
fixed_effects <- c("NativeLanguage", "CenteredFrequency") # all fixed effects specified in artificial_glmer
simvar <- "Subject" # which random variable do we want to vary in the simulation?

# ------------------------------------------ #
# SIMULATION PARAMETERS
steps <- c(20,50,100,150,200) # which sample sizes do we want to look at?
critical_value <- 2 # which t/z value do we want to use to test for significance?
n_sim <- 1000 # how many single simulations should be used to estimate power?

# ------------------------------------------ #
# INCLUDE SESOI SIMULATION
SESOI <-c(-4.3,  0.30 ,-0.34, -0.27) # specify SESOI (15% smaller betas)


# ------------------------------------------ #
# RUN SIMULATION WITH MIXEDPOWER
power <- mixedpower(model = model, data = data,
                       fixed_effects = c("NativeLanguage", "Frequency"),
                       simvar = "Subject", steps = steps,
                       critical_value = critical_value, n_sim = n_sim,
                       SESOI = SESOI)


# ------------------------------------------ #
# LOOK AT RESULTS
power

saveRDS(power, file="mixedpower-simulation.RDS")
power <- readRDS(file="mixedpower-simulation.RDS")
# ------------------------------------------ #
# PLOT THE RESULTS
multiplotPower(power)




```




```{r}
# GENRE <- c("news","research","artistic")
# POOL <- c("data-collar","blue-collar")
# 
# 
# 
# x <- sample(x = 1:10, size  = 5, replace = TRUE) #randomly sample from min to max y times with replacement
# y <- sample(x = c("data-collar","blue-collar"), size  = 5, replace = TRUE) #randomly sample from min to max y times with replacement
# 
# sim <- cbind(x,y)
```










# EXPLORATORY DATA ANALYSIS

What questions do we expect we will want to answer? 

Are the SDs affected by particular GRAPH? 
Are the SDs consistent across participants for a particular GRAPH?
Do the SDs differ across samples for a particular GRAPH? 
How accurate are subjects' confidence in their MAKER and TOOL attributions? 



## WIP 

```{r}


## PAIRPLOT OF ALL NUMERIC VARS BY GRAPH
#select all numeric columns and graph
df <- df_responses %>% select(
  graph, where(is.numeric)) #select all numeric columns

ggscatmat(df, columns = 3:9, color = "graph", alpha = 0.8) + 
  ggtitle("MAKER ATTRIBUTIONS BY GRAPH")

# SIMULATIONS
# 
# df_sim$graph = df$graph
# 
# 
# #CREATE A COPY OF DF WITH NO DATA 
# 
# set.seed(8)
# # x = runif(n = 500, min=0, max=100)
# df_sim <- df %>% mutate(
#   Q_MAKER_ID_CONF = round(rnorm( n = nrow(df), mean = 50, sd = 20),0)
# ) 
# 
# 
# 
# 
# glimpse(df_sim)
# 
# 
# gf_histogram(~df_sim$Q_MAKER_ID_CONF)
# 
# df_sim <- cbind(df_sim, df$graph)
# 
# 
# library(simstudy)
# #DEFINE PARAMETERS
# rm(def)
# def <- defData(varname = "lower", dist = "uniform", formula = "0;0")
# def <- defData(def, varname = "upper", dist = "uniform", formula = "100;100")
# def <- defData(def, varname = "duration_sec", dist = "normal", formula = 50, variance=2)
# def <- defData(def, varname = "Q_MAKER_ID_CONF", dist = "normal", formula = 50, variance = 15)
# def <- defData(def, varname = "Q_MAKER_AGE", dist = "poisson",formula = 50)
# (sim <- genData(5,def))
# sim$Q_MAKER_GENDER = sim$Q_MAKER_AGE



```







## PLATFORM
**What social media platform do participants choose to engage with?" 

```{r engagement}

## PLOT  participant PLATFORM X POOL 
# plot(df_responses$PLATFORM ~ df_responses$POOL)
gf_bar( ~ PLATFORM, fill = ~ POOL, data = df_subjects) + 
  facet_grid( POOL ~ .) + 
  theme_minimal() + 
  ggtitle( label = "Participant PLATFORM choice by POOL")
ggbarstats( data = df_subjects, 
            x = PLATFORM, y = POOL) + 
ggtitle( label = "Participant PLATFORM choice by POOL")


```
