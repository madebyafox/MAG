---
title: "S3 DATA WRANGLING—SUBMISSION 1006"
author: "ANONYMIZED"
date: "2025-02-24"
output:
  html_document:
    theme: flatly
    code_folding: hide
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 5
  pdf_document:
    toc: yes
    toc_depth: '4'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(psych) #describe()
library(tidyverse) #all the things
library(magrittr) #special pipes like %<>%
library(lubridate) #dealing with dates
library(kableExtra) #printing tables

#EXPLORATORY DATA ANALYSIS
library(summarytools) #data quality
library(qacBase) #EDA

#CONFIG
options(readr.show_col_types = FALSE) #don't show coltypes on read_csv
n_blocks = 6 #number of stimulus blocks in study design

```

*This notebook contains code to wrangle raw data from a qualtrics survey (STUDY 4) into a single normalized dataset of (valid) participant responses.*

The following dataframes are created:

-   `df_data` represents **response data** for all valid participants (wide format) — answers are not stored as factors; not useful for numeric analysis but just as a record of participant-level responses

-   `df_participants` represents **demographic data** for all valid participants

-   `df_qda_wide` includes all valid responses in wide format, to be used for free response data analysis (wide)

-   `df_qda_long` represents response and demographic data for all valid participants (used to generate a spreadsheet for analysis for free response data) *at the trial (i.e. stimulus) level* (i.e. long).

-   `df_questions` include valid responses at the most granular level, where each row refers to a participant+stimulus+question (long format) [318p X 5s X 28q]

-   `df_sd_questions_long` includes only the semantic differential-type questions (long)

-   `df_sd_questions_wide` is a wide version of the `df_sd_questions` dataframe useful for some graphs (318p X 11q = 3498 rows)

-   `df_tools` contains responses to the tool id and tool confidence questions, where tool_id is a multi-select Q

-   `df_actions` contains responses to the action id and action confidence questions, where df_action is a multi-select Q

-   `df_graphs_full` is a stimulus (ie. graph image) level dataframe where each row contains columns for a participant and all the Qs for that graph

-   `df_graphs` is df_graphs_full w/o the free response and multiselect Qs

# STANDARDIZE

This notebook takes a raw data files from (1) Qualtrics surveys (Study 3), standardizing the format for further data analysis consistent with the data structures for Studies 1-2 (and pilot Study 0). Note that all raw data comes from Qualtrics, and each Qualtrics survey includes a different stimulus block (set of 5 stimuli).


## Import Configuration Files

*Import files with reference information for stimuli `ref_stimuli` and qualtrics surveys `ref_surveys`.*

```{r setup-references, message=FALSE, warning = FALSE}

############## IMPORT STIMULI FILE
#contains data for each stimulus used 
ref_stimuli <- read_csv("data/input/REFERENCE/stimuli.csv", col_names = TRUE) %>% 
  mutate(
    BLOCK = as.factor(BLOCK), 
    STIMULUS_CATEGORY = as.factor(CATEGORY),
    ID = as.factor(ID),
    MAKER_ID = as.factor(MAKER_ID)) %>% 
  select(-CATEGORY)



############## STUDY ID FILE
#most blocks were run as separate qualtrics surveys with diffferent recruitments in Prolific
ref_surveys <- read_csv("data/input/REFERENCE/studies.csv", col_names = TRUE) %>%
  mutate(
    ID.Study = as.factor(ID.Study),
    Assigned.Block = as.factor(Assigned.Block),
    Distribution = as.factor(Distribution),
    Prolific.Name = as.factor(Prolific.Name),
    Qualtrics.URL = as.factor(Qualtrics.URL),
    Qualtrics.Survey = as.factor(Qualtrics.Survey),
    Sample = as.factor(Sample),
    Study = as.factor(Study)
)


```

## Define Labels

*Define labels used in survey questions and response options; used to generate labels for graphs and filtering of datasets in analysis files.*

```{r setup-labels}

############## BUILD LABELS
ref_stim_id <- levels(ref_stimuli$ID)
ref_blocks <- c("block1", "block2", "block3", "block4", "block5", "block6")

ref_cat_questions <- c("ENCOUNTER","ID","AGE","GENDER")
ref_conf_questions <- c("ID_CONF","AGE_CONF","GENDER_CONF")
ref_sd_questions <-  c("DESIGN","DATA","POLITICS", "TRUST","ALIGN","BEAUTY","INTENT")
ref_sd_questions_z <-  c("DESIGN_z","DATA_z","POLITICS_z", "TRUST_z","ALIGN_z","BEAUTY_z","INTENT_z")
ref_sd_questions_wide <- c("PRE_DESIGN",
                           "PRE_DATA",
                           "PRE_POLITICS", 
                           "PRE_TRUST",
                           "PRE_ALIGN",
                           "PRE_BEAUTY",
                           "PRE_INTENT",
                           "POST_DESIGN",
                           "POST_DATA",
                           "POST_POLITICS",
                           "POST_TRUST",
                           "POST_ALIGN",
                           "POST_BEAUTY",
                           "POST_INTENT")

ref_sd_questions_wide_z <- c(
                           "PRE_DESIGN_z",
                           "PRE_DATA_z",
                           "PRE_POLITICS_z", 
                           "PRE_TRUST_z",
                           "PRE_ALIGN_z",
                           "PRE_BEAUTY_z",
                           "PRE_INTENT_z",
                           "POST_DESIGN_z",
                           "POST_DATA_z",
                           "POST_POLITICS_z",
                           "POST_TRUST_z",
                           "POST_ALIGN_z",
                           "POST_BEAUTY_z",
                           "POST_INTENT_z")

############## GRAPH LABELS
left <- c("professional","professional",
          "left-leaning","untrustworthy","does NOT share","NOT at all",
          "inform")

right <- c("layperson","layperson", 
           "right-leaning","trustworthy", "DOES share", "very much",
           "persuade")

category <- c("COMPETENCY","COMPETENCY",
              "MAKER","MAKER","MAKER","CHART","CHART")
              
ref_labels <- as.data.frame(cbind(ref_sd_questions, left,right,category))
rownames(ref_labels) <- ref_sd_questions

write.csv(ref_labels, file = "data/input/REFERENCE/ref_label_S3.csv", na="")
saveRDS(ref_labels, file = "data/input/REFERENCE/ref_labels_S3.rds")


### LABELS FOR ABS VALUE OF SD QUESTIONS
ref_sd_questions_abs <-c("DESIGN","DATA","POLITICS", "TRUST","ALIGN","BEAUTY","INTENT")

left <- c("(neutral)","(neutral)",
          "(neutral)","(neutral)","(neutral)","(neutral)","(neutral)")

right <- c("professional/layperson","professionaL/layperson",
           "left-leaning/right-leaning","untrustworthy/trustworthy", "does NOT share/DOES share",
            "NOT at all/VERY much","inform/persuade" )


ref_labels_abs <- as.data.frame(cbind(ref_sd_questions_abs,left,right,category))
rownames(ref_labels_abs) <- ref_sd_questions_abs

write.csv(ref_labels_abs, file = "data/input/REFERENCE/ref_labels_abs_S3.csv", na="")
saveRDS(ref_labels_abs, file = "data/input/REFERENCE/ref_labels_abs_S3.rds")



```

## Define Factors

*Define order of factors for multiple-choice variables*

```{r define-factor-orders}

## set order of several factor vars used in plots 
order_times = c("PRE","POST")
order_study = c("Study1","Study2","Study3","Study0") ##NEW for VIS
order_sample = c("TUMBLR","DATACOLLAR","BLUECOLLAR", "GENERAL") ## NEW for VIS
order_distribution = c("TUMBLR","PROLIFIC")
order_maker = c("individual","organization","education","business","news","political")
order_age = c("boomer", "gen-x","millennial","gen-z")
order_gender = c("Other","Female","Male" )
order_encounter = c("scroll", "engage")

```

## Import Raw Files

*Here we import raw qualtrics data files for each survey, and normalize column names to produce a single raw data file including all attempts at completing all the surveys: `df_raw`. This intermediary file is not used for analysis, but rather for further wrangling into participant, trial, and question level files*

```{r IMPORT-RAW, message=FALSE, warning=FALSE}

#1. IMPORT RAW DATA FILES ########################################################
#### RAW DATA ####################################################################
# will always be the unaltered version of imported data
# 1 row per subject 
df_raw_study3 <- read_csv("data/input/CLEAN/CLEAN_MAG_S2_PROLIFIC_GENERAL_1_STUDY4_PREPOST.csv", col_names = TRUE)

# drop first two rows (these are qualtrics_specs rows)
df_raw_study3 <- df_raw_study3[-c(1:2),]

# RETROFIT SOME COLNAMES FOR COMPATIBILITY WITH TUMBLR 
df_raw_study3 <- df_raw_study3 %>% 
  #drop T_BROWSER cols [these are blank]
  select(-contains("T_BROWSER"), -T_EMAIL) %>% 
  mutate(
    Q_RelevantIDDuplicate = NA, 
    Q_RelevantIDDuplicateScore = NA, 
    Q_RelevantIDFraudScore = NA, 
    Q_RelevantIDLastStartDate = NA, 
    RANDOM_BLOCK = NA
  ) %>% rename_with(
    stringr::str_replace, 
      pattern = "P_BROWSER", replacement = "BROWSER",
  ) %>% 
  dplyr::rename(
    BROWSER_OS = `BROWSER_Operating System`
  ) %>% mutate_all(funs(str_replace(., "millenial", "millennial")))


# SELECT RELEVANT COLS
df_raw <- df_raw_study3 %>% 
  #reorder 
  select( RANDOM_BLOCK, 
          End_State,
          StartDate:randomize_common, 
          ID_PROLIFIC:ID_SESSION, 
          D_gender:FEEDBACK, 
          PROLIFIC_PID: stimulus_common,
          Q_RelevantIDDuplicate: Q_RelevantIDLastStartDate,
          `1_Q_B0_ENCOUNTER`   : `1_Q_B0_LATENCY-P_Click Count`,
          `1_Q_B1_loop-number` : `1_Q_B1_LATENCY-P_Click Count`,
          `2_Q_B1_loop-number` : `2_Q_B1_LATENCY-P_Click Count`,
          `3_Q_B1_loop-number` : `3_Q_B1_LATENCY-P_Click Count`,
          `4_Q_B1_loop-number` : `4_Q_B1_LATENCY-P_Click Count`,
          QUALITY_CHECK_TEXT
) 


#DROP WIP DATAFRAMES 
rm(df_raw_study3)

```

## Wrangle Standardized File

Here we drop irrelevant columns (qualtrics junk) and set factors. The resulting `df_data` frame is wide (1 row/participant, but includes redundant columns for the blocks they were not assigned to).

```{r WRANGLE-FACTORS, warning=FALSE}

#1A. WRANGLE MASTER PARTICIPANT-LEVEL DF  #########################################################
################################################################################################
#### MASTER WIDE FORMAT DATA FRAME [1 row / valid qualtrics submission] ################

##RENAME AND SET CORRECT DATA TYPES
df_data <- df_raw %>% 
  select(
    -EndDate, -IPAddress, -RecordedDate,
    -RecipientLastName, -RecipientFirstName, -RecipientEmail,
    -ExternalReference, -LocationLatitude, -LocationLongitude, 
    -DistributionChannel, -UserLanguage, -Q_RecaptchaScore,
    -BROWSER_Version, -BROWSER_Resolution, 
    -CONSENT, -ELIGIBILITY, 
    -randomize_common,
    #hidden q that controls common stimulus url
    -stimulus_common, 
    -contains("First Click"), -contains("Last Click"), -contains("Click Count"),
    -ID_PROLIFIC, -ID_STUDY, -ID_SESSION #redundant to other cols 
  )  %>% 
  dplyr::rename(
    duration.sec = `Duration (in seconds)`,
    EndState = End_State, 
    TerminateFlag = Q_TerminateFlag,
    Source = Status, #where the survey originated from (should not be preview or test)
    PLATFORM = Q_PLATFORM,
    ID.Qualtrics = ResponseId,
    ID.Prolific = PROLIFIC_PID,
    ID.Study = STUDY_ID,
    ID.Session = SESSION_ID,
    # P_BROWSER_OS = `P_BROWSER_Operating System`,
    # T_BROWSER_OS = `T_BROWSER_Operating System`,
    SCREEN_workFunction_TEXT = SCREEN_workFunction_22_TEXT, 
    SCREEN_socialMedia_TEXT = SCREEN_socialMedia_18_TEXT,
    D_politicalParty_OTHER = D_politicalParty_4_TEXT,
    D_politicsSocial = D_politicsSocial_1,
    D_politicsFiscal = D_politicsFiscal_2
 ) %>% 
  mutate(
    #SET FACTORS 
    D_politicsSocial = as.numeric(D_politicsSocial),
    D_politicsFiscal = as.numeric(D_politicsFiscal),
    ID.Study = factor(ID.Study),
    ID.Qualtrics = factor(ID.Qualtrics),
    ID.Prolific = factor(ID.Prolific),
    ID.Session = factor(ID.Session),
    PLATFORM = factor(PLATFORM),
    Source = factor(Source),
    Finished = as.logical(Finished),
    TerminateFlag = factor(TerminateFlag),
    EndState = factor(EndState), 
    D_gender = factor(D_gender), 
    D_gender_collapsed = fct_collapse(D_gender, 
                                male = "Male", 
                                female = "Female", 
                                other = c("Non-binary / third gender", "Prefer not to say", "Prefer to self-describe")),
    D_age = factor(D_age), 
    D_income = factor(D_income, 
                      levels = c(
                        "Prefer not to say",
                        "Less than $25,000",
                        "$25,000-$49,999"  ,
                        "$50,000-$74,999"  ,
                        "$75,000-$99,999"  ,
                        "$100,000-$149,999",
                        "$150,000 or more" 
                      )),
    D_employmentStatus = factor(D_employmentStatus),
    duration.sec = as.numeric(duration.sec), #weird booleans should only be for the test generator
    duration.min = round(duration.sec/60,2),
    Progress = as.numeric(Progress), 
    D_ed = factor(D_education),
    D_education = forcats::fct_na_value_to_level( D_education, level="NA"),
    D_education = forcats::fct_collapse( D_education,
                                no_data = "NA",
                                less_high_school = c("Some high school or less"),
                                high_school = c("High school diploma or GED"),
                                some_college = c("Some college, but no degree", "Some college, no degree"),
                                associates =c( "Associates or technical degree"),
                                undergrad = c("Bachelor’s degree","Bachelor's degree"),
                                grad = c("Graduate or professional degree (MA, MS, MBA, PhD, JD, MD, DDS etc.)",
                                         "Graduate or professional degree (MA, MS, MBA, PhD, JD, MD, DDS, etc)")
    ),
    D_education = factor(D_education,
                                       levels = c("no_data", "less_high_school","high_school", "some_college",
                                         "associates", "undergrad", "grad"),
                                       labels = c("NA", "some high school or less","high school diploma or GED ",
                                                  "some college", "associates or technical degree",
                                                  "undergradudate degree", "graduate or professional degree"),
                                       ),
    D_education_collapsed = forcats::fct_na_value_to_level( D_education, level="NA"),
    D_education_collapsed = forcats::fct_collapse(D_education_collapsed,
                                         hs_or_less = c("NA","some high school or less","high school diploma or GED "),
                                         ugrad = c("some college", "associates or technical degree",
                                                  "undergradudate degree"),
                                         grad = c("graduate or professional degree")
                                         ),
    D_politicalParty = factor(D_politicalParty, levels = c("Democrat", "Other", "No preference", "Independent", "Republican")),
    D_age = factor(D_age, 
                   levels = c("18-24 years old" ,
                              "25-34 years old" ,
                              "35-44 years old" ,
                              "45-54 years old" ,
                              "55-64 years old" ,
                              "65+ years old"   ), 
                   labels = c("18-24", "25-34","35-44","45-54","55-64","65+ years"))
  ) %>%
  #REPLACE RANDOM TRAILING _1 AND _65 FROM QUALTRICS
  rename_with( .cols = contains('_65'), .fn = ~str_replace(.,  pattern = '_65', replacement = '')) %>% 
  rename_with( .cols = contains('_1'), .fn = ~str_replace(.,  pattern = '_1', replacement = '')) %>% 
  #RM _PAGE Submit from LATENCY
  rename_with( .cols = contains('_Page Submit'), .fn = ~str_replace(.,  pattern = '_Page Submit', replacement = '')) %>% 
  #CHANGE DETAIL QUESTION DELIMITER FOR PIVOT PURPOSES 
  rename_with( .cols = contains('_CHART_'), .fn = ~str_replace(.,  pattern = '_CHART_', replacement = '_CHART-')) %>% 
  #CHANGE DETAIL QUESTION DELIMITER FOR PIVOT PURPOSES 
  rename_with( .cols = contains('_MAKER_'), .fn = ~str_replace(.,  pattern = '_MAKER_', replacement = '_MAKER-')) %>% 
  #CHANGE DETAIL QUESTION DELIMITER FOR PIVOT PURPOSES 
  rename_with( .cols = contains('_AGE_'), .fn = ~str_replace(.,  pattern = '_AGE_', replacement = '_AGE-')) %>% 
  #CHANGE DETAIL QUESTION DELIMITER FOR PIVOT PURPOSES 
  rename_with (.cols = contains('_GENDER_'), .fn = ~str_replace(., pattern = '_GENDER_', replacement = '_GENDER-')) %>% 
  #CHANGE DETAIL QUESTION DELIMITER FOR PIVOT PURPOSES 
  rename_with (.cols = contains('_TOOL_'), .fn = ~str_replace(., pattern = '_TOOL_', replacement = '_TOOL-'))%>%
  ## SPECIAL FOR S4; RENAME B0 COLS WITH 0_Q_B0 FROM 1_Q_B0 caused by qualtrics changes
  rename_with(
    stringr::str_replace, 
      pattern = "1_Q_B0", replacement = "0_Q_B0",
  ) %>% 
  select(
    #reordering
    RANDOM_BLOCK:Progress, 
    Finished, EndState, TerminateFlag, 
    Q_RelevantIDDuplicate:Q_RelevantIDLastStartDate,
    ID.Qualtrics, 
    ID.Prolific : ID.Session, 
    duration.sec, duration.min,
    BROWSER_Browser : BROWSER_OS, 
    D_gender_collapsed, D_gender, D_gender_4_TEXT,
    D_race,D_education_collapsed, D_education,
    D_employmentStatus:D_politicsFiscal,
    SCREEN_workMethod: SCREEN_socialMedia_TEXT, 
    PURPOSE, FEEDBACK, PLATFORM,
    `0_Q_B0_ENCOUNTER`: `4_Q_B1_LATENCY-P`,
    QUALITY_CHECK_TEXT
  ) 

##### JOIN SURVEY-LEVEL DATA 
df_data <- dplyr::left_join(df_data, ref_surveys, by="ID.Study") 

#SET IDS AND ASSIGNED BLOCK TO HANDLE PROLIFIC AND TUMBLR 
df_data <- df_data %>% 
  mutate(
    # SET ASSIGNMENT BLOCK FOR TUMBLR
    Assigned.Block = if_else( (Distribution =="TUMBLR"), RANDOM_BLOCK, Assigned.Block),
    Assigned.Block = factor(Assigned.Block), 
    # PID = if_else( (Distribution =="TUMBLR"), ID.Qualtrics, ID.Prolific),
    PID = factor(ID.Qualtrics),
    Distribution = factor(Distribution, levels=order_distribution), ## ADDED FACTOR ORDER TO KEEP TUBMLR AS FIRST 
    Sample = fct_recode(Sample, TUMBLR= "tumblr", BLUECOLLAR = "blue-collar", DATACOLLAR = "data-collar", GENERAL="general-prolific"), #recode factor levels
    Sample = factor(Sample, levels= order_sample), #set level order
    Study = factor(Study, levels = order_study) #set level order
  ) %>% #DROP RANDOM_BLOC COLUMNS
  select (-RANDOM_BLOCK) %>% 
  select(
    #REORDER
    PID, 
    Distribution, 
    Assigned.Block,
    ID.Qualtrics:ID.Session,
    EndState,
    StartDate: Q_RelevantIDLastStartDate, 
    Prolific.Name, Qualtrics.Survey,  Qualtrics.URL, Description, Sample, Study, 
    duration.sec:PLATFORM,
     `0_Q_B0_ENCOUNTER`: `4_Q_B1_LATENCY-P`,
    QUALITY_CHECK_TEXT
  ) 

#DROP WIP DATAFRAMES 
rm(df_raw)

```


# CLEANING

*Here we apply exclusion criteria in order to reduce the raw participant data in `df_data` to a dataframe of valid participant data `df_subjects`. We remove unneeded columns (i.e. qualtrics configuration columns, etc) and transform columns to the the appropriate data types for further analysis.*


Participants were *excluded* from the sample for the following reasons:

-   **abandoned**; Finished = False and Progress \< 100%
-   **fails consent or pre-screening**, Finished = TRUE, Progress = 100%, Q_TerminateFlag = "Screened"
-   **didnot-follow-instructions** free responses indicate they misinterpred the question (most commonly they describe the graph rather than their reactions/judgements/impressions of it)
-   **illegible-english** free responses text is largely illegible
-   additionally, free responses were inspected in Qualtrics for evidence of vague/low effort answers, and those flagged by Qualtrics for straighlining, likely AI generated text, and likely bot-generated.  These are noted as comments in the `QUALITY_CHECK_TEXT` column

A dataframe `df_exclude` is saved, including **response data** for participants who did not meet inclusion criteria (wide format)

```{r CLEAN-MASTER}
#1B CLEAN MASTER PARTICIPANT-LEVEL DF  #########################################
#### SEGREGATE PARTICIPANTS WHO DID NOT COMPLETE ###############################
## [1 row / qualtrics submission] ################
## NOTE it is common for prolific participants to fail the 
## screening verification, and then try again but change their 
## screening verification answers (ie. one prolific ID for multiple qualrics IDs)
df_exclude <- df_data %>% 
  filter( 
    ( !is.na(TerminateFlag) | Finished == FALSE | EndState != "COMPLETE" |  (QUALITY_CHECK_TEXT !="NA"))
  ) %>% 
  select(
    PID, Distribution, ID.Qualtrics, ID.Prolific, ID.Study, Assigned.Block, Study, Source, Progress, 
    Finished, TerminateFlag, EndState,StartDate, duration.min, 
    D_gender:D_politicsFiscal, SCREEN_workMethod:FEEDBACK, Prolific.Name:Study, QUALITY_CHECK_TEXT
  )  %>% 
  mutate(
    EndState = if_else( (QUALITY_CHECK_TEXT!="NA"), QUALITY_CHECK_TEXT, EndState),
    EndState = if_else( (Progress < 100), "abandoned", EndState),
    EndState = if_else( (str_detect(EndState,"screen")), "screened", EndState),
    EndState = if_else( (TerminateFlag == "Screened" & is.na(EndState)), "screened", EndState),
    EndState = factor(EndState)
  )
write.csv(df_exclude, file = "data/output/Study_3/df_exclude_S3.csv", na="")
saveRDS(df_exclude, file = "data/output/Study_3/df_exclude_S3.rds")



#### MASTER VALID DATA [WIDE] 1 row per qualtrics entry #########################
## [1 row / qualtrics submission] ################
df_data <- df_data %>% filter(
  PID %nin% df_exclude$PID
  # (Finished == TRUE ) & is.na(TerminateFlag)
) %>% mutate(
  EndState = droplevels(EndState),
  ID.Prolific = droplevels(ID.Prolific),
  ID.Qualtrics = droplevels(ID.Qualtrics), 
  PID = droplevels((PID))
) %>% 
  ### NEW FOR S4
  select(-c(Q_RelevantIDDuplicate:Q_RelevantIDLastStartDate))


##SANITY CHECKS ON EXLUSIONS
#sanity check === SHOULD BE O
#no qualtrics surveys in good data that weren't finished
print("Number of PID entries in df_data AND nofinish/excluded? [should be 0]")
sum(df_data$PID %in% df_exclude$PID)

#sanity check === SHOULD BE O
#no duplicated PROLIFIC ids in good data 
print("Number of PIDs duplicated in df_data print [should be 0]")
sum(duplicated(df_data$PID))
```

# WRANGLE

*Reshape data into files for analysis*


The following dataframes are created:

-   `df_data` represents **response data** for all valid participants (wide format)

-   `df_participants` represents **demographic data** for all valid participants
-   `df_qda_wide` includes all valid responses in wide format, to be used for free response data analysis (wide)
-   `df_qda_long` represents response and demographic data for all valid participants (used to generate a spreadsheet for analysis for free response data) *at the trial (i.e. stimulus) level* (i.e. long).

The following dataframes are created:

-   `df_questions` include valid responses at the most granular level, where each row refers to a participant+stimulus+question (long format) with pre-and post ad separate columns

-   `df_sd_questions_long` includes only the semantic differential-type questions (long)

-   `df_sd_questions_wide` is a wide version of the `df_sd_questions` dataframe useful for some graphs (318p X 11q = 3498 rows)

-   `df_tools` contains responses to the tool id and tool confidence questions, where tool_id is a multi-select Q

-   `df_actions` contains responses to the action id and action confidence questions, where df_action is a multi-select Q

-   `df_graphs_full` is a stimulus (ie. graph image) level dataframe where each row contains columns for a participant and all the Qs for that graph

-   `df_graphs` is df_graphs_full w/o the free response and multiselect Qs

-   `df_questions` include valid responses at the most granular level, where each row refers to a participant+stimulus+question (long format) [318p X 5s X 28q]

-   `df_sd_questions_long` includes only the semantic differential-type questions (long)

-   `df_sd_questions_wide` is a wide version of the `df_sd_questions` dataframe useful for some graphs (318p X 11q = 3498 rows)

-   `df_tools` contains responses to the tool id and tool confidence questions, where tool_id is a multi-select Q

-   `df_actions` contains responses to the action id and action confidence questions, where df_action is a multi-select Q

-   `df_graphs_full` is a stimulus (ie. graph image) level dataframe where each row contains columns for a participant and all the Qs for that graph

-   `df_graphs` is df_graphs_full w/o the free response and multiselect Qs


## Sanity Check
```{r SANITY-CHECK}

########## CHECK BLOCK COUNTS 
#############################################################################
# title = "Participants by Condition and Data Collection Modality"
# cols = c("Control Condition","Impasse Condition","Total for Period")

title = "Number of abandoned/screened/rejected attempts "
cols = c("Block","Study1","Study2","Study3","Study0","sum")
cont <- table(df_exclude$Assigned.Block, df_exclude$Study)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

title = "Number of successful surveys"
cols = c("Assigned.Block", "Sum")
cont <- table(df_data$Assigned.Block)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

title = "Number of successful surveys by distribution and block"
cols = c("Study", "Block-1","Block-2","Block-3","Block-4","Block-5","Block-6", "Sum")
cont <- table(df_data$Study, df_data$Assigned.Block)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

```

## Create MASTER data file

`df_data` represents **response data** for all valid participants (wide format) — answers are not stored as factors; not useful for numeric analysis but just as a record of participant-level responses

```{r CREATE-RESPONSE}

#WRITE  A CSV FILE WITH RESPONSE DATA FOR VALID PARTICIPANTS (NOT EXCLUDED) in wide format
## not formatted for anaysis in R
write.csv(df_data, file = "data/output/Study_3/df_data_S3.csv", na="")
saveRDS(df_data, file = "data/output/Study_3/df_data_S3.rds")

```

## Create DEMOGRAPHICS File
`df_participants` contains all valid participants in WIDE format
```{r CREATE-DEMOGRAPHICS}

##### CREATE PARTICIPANT LEVEL DEMOGRAPHIC DATAFRAME 
df_participants <- df_data %>% 
  select(
    PID:Assigned.Block, 
    EndState, Sample, Study, 
    duration.sec, duration.min, 
    contains("D_"), 
    contains("SCREEN_"),
    PLATFORM
  ) %>% select(-contains("_ID"))

#WRITE  A CSV FILE WITH DEMOGRAPHIC DATA ALL VALID PARTICIPANTS (NOT EXCLUDED) in wide format
write.csv(df_participants, file = "data/output/Study_3/df_participants_S3.csv", na="")
saveRDS(df_participants, file = "data/output/Study_3/df_participants_S3.rds")


```

## Create QDA WIDE

Two files are created for the purpose of qualitative data analysis: 
-   `df_qda_wide`: PARTICIPANT level:  includes all valid responses in wide format, to be used for free response data analysis (wide)
-   `df_qda_long`: GRAPH level:  represents response and demographic data for all valid participants (used to generate a spreadsheet for analysis for free response data) *at the trial (i.e. stimulus) level* (i.e. long).

```{r CREATE-QDA}

#1 CREATE PARTICIPANT LEVEL DFS FOR QDA ########################################
## save participant-level data file for qda validation 
## this does NOT contain excluded participants 
## 1 ROW / PARTICIPANT 
df_qda_wide <- df_data
write.csv(df_data, file = "data/output/Study_3/df_qda_wide_S3.csv", na="")

```

## Create QDA LONG
```{r CREATE-QDA-LONG}

#2 CREATE TRIAL LEVEL DFS FOR QDA ###############################################
#### CHART LEVEL DATA FRAME (LONG) FOR QDA (incl demographics) ##################
#### INCLUDES PILOT DATA FROM DATACOLLAR BLUECOLLAR PROLIFIC RECRUITMENT ########
# 1 ROW / participant X GRAPH including demographics 
# UNRAVEL TO QUESTIONS
df_qda_long <- df_data %>% 
  pivot_longer( #PIVOT ON stimulus
    cols = contains("_Q_"),
    names_to = c("stimulus","dummy","BLOCK","QUESTION"),
    values_to = c("value"),
    names_sep = "_"
) %>% select(-dummy) %>%
  unite(
   BLOCK:stimulus, col="STIMULUS", sep="-", remove=FALSE
) %>% 
  mutate(
    BLOCK = factor(BLOCK),
    STIMULUS = factor(STIMULUS),
    # QUESTION = str_replace_all(QUESTION,"-","_"),
    QUESTION = factor(QUESTION),
    STIMULUS_CATEGORY = str_remove(STIMULUS,"B.-"),
    STIMULUS_CATEGORY = factor(STIMULUS_CATEGORY,
                  levels=c("0","4","3","2","1"),
                  labels= c("F","D","C","B","A"))
  ) %>% 
  select(-stimulus) %>%
# RE-RAVEL UP TO STIMULI
  filter(!is.na(value)) %>% 
   pivot_wider(
    names_from = QUESTION,
    values_from = value 
  ) %>%
  tidyr::unnest()  %>%  
  # handle r coerces values to lists
  mutate(
    # across(contains("MAKER_ID") | contains("MAKER_GENDER") | contains("MAKER_AGE"), factor),
    across(c("ENCOUNTER","ID", "AGE", "GENDER","ENCOUNTER-P","ID-P", "AGE-P", "GENDER-P"),factor),
    across(contains("CONF") | contains("LATENCY"), as.numeric),
    across(DESIGN:INTENT, as.numeric),
    across(`DESIGN-P`:`INTENT-P`, as.numeric),
    ENCOUNTER = factor(ENCOUNTER),
    # loop_number = as.numeric(loop_number),
    # loop_number = ifelse(is.na(loop_number), 0, loop_number),
    LATENCY = round(LATENCY/60,2), #CHANGE TO MINS
    `LATENCY-P` = round(`LATENCY-P`/60,2) #CHANGE TO MINS
  )
#WRITE A CSV FILE AS THE BASIS FOR THE QUALITATIVE DATA ANALYSIS
write.csv(df_qda_long, file = "data/output/Study_3/df_qda_long_S3.csv", na="")


```



*Here we pivot response data from valid (non-pilot) participants to be represented at the QUESTION (i.e. semantic differential) and TRIAL (ie. question+stimulus) levels.*


## Create QUESTION level (longest) 
`df_questions` is at the graph-question level, but includes _all_ questions, both categorical, free response, and numeric. The pre-post measures are represented in separate rows, with timepoint indicated in the `TIME` field.  

```{r QUESTION-LONG, warning=FALSE}

#### QUESTION LEVEL DATA FRAME (LONGEST) ##########################
# unravel ALL the way down to questions 
# 1 row per participant-graph-question-timepoint ———— with pre and post measures as separate rows
df_questions_long <- df_data %>% 
  select(
    PID, duration.min,  Assigned.Block,
    Sample, Study, Distribution, PLATFORM, 
    D_gender_collapsed:D_politicsFiscal, 
    contains("_Q_")
  )  %>% 
  pivot_longer( #PIVOT ON stimulus
    cols = contains("_Q_"),
    names_to = c("stimulus","dummy","BLOCK","QUESTION"),
    values_to = c("value"),
    names_sep = "_"
  ) %>% select(-dummy) %>% 
  unite(
   BLOCK:stimulus, col="STIMULUS", sep="-", remove=FALSE
  ) %>%
  mutate(
    TIME = case_when(
      str_detect(QUESTION,"-P") ~"POST",
      !str_detect(QUESTION,"-P") ~"PRE"),
    QUESTION = str_replace_all(QUESTION,"-P","")
  ) %>% 
  mutate(
    TIME = factor(TIME, levels=order_times),
    BLOCK = factor(BLOCK),
    STIMULUS = factor(STIMULUS),
    QUESTION = str_replace_all(QUESTION,"-","_"),
    QUESTION = factor(QUESTION, 
                      levels = c(
                        "ENCOUNTER",    
                        "ID",        
                        "ID_CONF",
                        "AGE", 
                        "AGE_CONF",
                        "GENDER",
                        "GENDER_CONF",
                        "DESIGN",  
                        "DATA",    
                        "POLITICS",
                        "TRUST", 
                        "ALIGN", 
                        "BEAUTY",  
                        "INTENT", 
                        "EXPLAIN",   
                        "LATENCY" )),
    STIMULUS_CATEGORY = str_remove(STIMULUS,"B.-"),
    STIMULUS_CATEGORY = factor(STIMULUS_CATEGORY,
                  levels=c("0","4","3","2","1"),
                  labels= c("F","D","C","B","A"))
    # tempblock = paste("B",as.character(Assigned.Block), sep="")
  ) %>% 
  select(-stimulus) %>% 
  filter(QUESTION !="loop_number") 

## WRITE DATAFRAME
write.csv(df_questions_long, file = "data/output/Study_3/df_questions_long_S3.csv", na="")
saveRDS(df_questions_long, file = "data/output/Study_3/df_questions_long_S3.rds")

```


## Create QUESTION level 
`df_questions` is at the graph-question level, but includes _all_ questions, both categorical, free response, and numeric. The pre-post measures are represented in separate COLUMNS (pre, post). 
```{r}
#### QUESTION LEVEL DATA FRAME (LONG, REPEATED) ##########################
# unravel ALL the way down to questions 
# 1 row per participant-graph-question ———— with pre and post measures as separate columns
# 1 row X 318p X 5g X 28q --> 55,520 rows
df_questions <- df_data %>% 
  select(
    PID, duration.min,  Assigned.Block,
    Sample, Study, Distribution, PLATFORM, 
    D_gender_collapsed:D_politicsFiscal, 
    contains("_Q_")
  )  %>% 
  pivot_longer( #PIVOT ON stimulus
    cols = contains("_Q_"),
    names_to = c("stimulus","dummy","BLOCK","QUESTION"),
    values_to = c("value"),
    names_sep = "_"
  ) %>% select(-dummy) %>% 
  unite(
   BLOCK:stimulus, col="STIMULUS", sep="-", remove=FALSE
  )  %>%
  ##pivot wider based on the value of the question name
  mutate(Time = ifelse(grepl("-P$", QUESTION), "POST", "PRE"),  # Create a new column for timepoint
         QUESTION = gsub("-P$", "", QUESTION)) %>%  # Remove "-P" from question names
  ##pivot wider
  pivot_wider(names_from = Time, values_from = value) %>% 
  mutate(
    BLOCK = factor(BLOCK),
    STIMULUS = factor(STIMULUS),
    QUESTION = str_replace_all(QUESTION,"-","_"),
    QUESTION = factor(QUESTION, 
                      levels = c(
                        "ENCOUNTER",    
                        "ID",        
                        "ID_CONF",
                        "AGE", 
                        "AGE_CONF",
                        "GENDER",
                        "GENDER_CONF",
                        "DESIGN",  
                        "DATA",    
                        "POLITICS",
                        "TRUST", 
                        "ALIGN", 
                        "BEAUTY",  
                        "INTENT", 
                        "EXPLAIN",   
                        "LATENCY" )),
    STIMULUS_CATEGORY = str_remove(STIMULUS,"B.-"),
    STIMULUS_CATEGORY = factor(STIMULUS_CATEGORY,
                  levels=c("0","4","3","2","1"),
                  labels= c("F","D","C","B","A"))
    # tempblock = paste("B",as.character(Assigned.Block), sep="")
  ) %>% 
  select(-stimulus) %>% 
  filter(QUESTION !="loop_number") 

## WRITE DATAFRAME
write.csv(df_questions, file = "data/output/Study_3/df_questions_S3.csv", na="")
saveRDS(df_questions, file = "data/output/Study_3/df_questions_S3.rds")
```


## Create SD questions (long)

`df_sd_questions_long` includes only the Semantic Differential questions (still in long format); 1 row per participant-graph-question

```{r SD-LONG}

### SD QUESTIONS LEVEL DATA FRAME (LONG) #####################
## 1 row per participant X sd question X block
## 318p X 11q X 5s = 17,490
df_sd_questions_long <- df_questions_long %>% 
  filter(QUESTION %in% ref_sd_questions) %>% 
  mutate(
    QUESTION = droplevels(QUESTION),
    value = as.numeric(value)
  )
## WRITE DATAFRAME
write.csv(df_sd_questions_long, file = "data/output/Study_3/df_sd_questions_long_S3.csv", na="")
saveRDS(df_sd_questions_long, file = "data/output/Study_3/df_sd_questions_long_S3.rds")

```

## Create SD questions (wide)
`df_sd_questions_wide` includes only the Semantic Differential questions (in wide format); 1 row per participant-question; but with a column for each stimulus


```{r QUESTION-WIDE}
#### SD QUESTION LEVEL DATA FRAME (wide-stim) ##########################
# ravel up one level from questions
# 1 row per participant-SDquestion with all blocks as cols for SD qs
# 318p X 11q = 3498 rows
df_sd_questions_wide <- df_questions %>%
  select(-BLOCK,-STIMULUS_CATEGORY) %>% #drop block in order to work at stimulus level
  filter(QUESTION %in% ref_sd_questions) %>% 
  pivot_wider(
    names_from = STIMULUS,
    values_from = c("PRE","POST") 
  ) %>%  
  tidyr::unnest() %>%  # handle r coerces values to lists
  mutate(
    across(contains("-") , as.numeric),
    QUESTION = droplevels(QUESTION)
  )
## WRITE DATAFRAME
write.csv(df_sd_questions_wide, file = "data/output/Study_3/df_sd_questions_wide_S3.csv", na="")
saveRDS(df_sd_questions_wide, file = "data/output/Study_3/df_sd_questions_wide_S3.rds")

```

## Create GRAPH/TRIAL level (all questions)
`df_graphs_full` contains 1 row / participant-graph (all qs as columns). The \_full indicates the file contains free response questions (useful for hover text on interactive visualizations)

```{r GRAPH LEVEL FULL}


## DFS FOR TRIAL LEVEL ANALYSIS   ######################################################
#### CHART LEVEL DATA FRAME (LONG) #####################################################
# roll partway back up from questions 
# 1 row per participant X graph 
# unnest https://stackoverflow.com/questions/58035452/pivot-wider-outputs-s3-vctrs-list-of-objects
df_graphs_full <- df_questions %>% 
  pivot_wider(
    names_from = QUESTION,
    values_from = c("PRE","POST")
  ) %>%  
  tidyr::unnest() %>%  # handle r coerces values to lists
  mutate(
    across(contains(c("ENCOUNTER","ID","AGE","GENDER")), factor),
    across(contains("_CONF") , as.numeric),
    across(contains("_LATENCY") , as.numeric),
    across(PRE_DESIGN:PRE_INTENT , as.numeric),
    across(POST_DESIGN:POST_INTENT , as.numeric),
    PRE_LATENCY = round(PRE_LATENCY/60,2), #CHANGE TO MINS
    POST_LATENCY = round(POST_LATENCY/60,2) #CHANGE TO MINS
  )
## WRITE DATAFRAME
write.csv(df_graphs_full, file = "data/output/Study_3/df_graphs_full_S3.csv", na="")
saveRDS(df_graphs_full, file = "data/output/Study_3/df_graphs_full_S3.rds")
```

## Create GRAPH/TRIAL level (SD and categorical)

```{r GRAPH-LEVEL-MAIN}
#7 DFS FOR TRIAL LEVEL ANALYSIS w/o free response ######################################################
#### CHART LEVEL DATA FRAME (LONG) ##########################
## SUBSET OF COLUMNS EXCLUDING THE FREE RESPONSES and MULTISELECT
df_graphs <- df_graphs_full %>% 
  select( !where(is.character)) %>% 
  mutate(
    ##re order factor levels
   PRE_ID = factor(PRE_ID, levels = order_maker),
   PRE_AGE = factor(PRE_AGE, levels = order_age),
   PRE_GENDER = factor(PRE_GENDER, levels = order_gender),
   PRE_ENCOUNTER = factor(PRE_ENCOUNTER, levels = order_encounter),
   POST_ID = factor(POST_ID, levels = order_maker),
   POST_AGE = factor(POST_AGE, levels = order_age),
   POST_GENDER = factor(POST_GENDER, levels = order_gender),
   POST_ENCOUNTER = factor(POST_ENCOUNTER, levels = order_encounter),
  )
## WRITE DATAFRAME
write.csv(df_graphs, file = "data/output/Study_3/df_graphs_S3.csv", na="")
saveRDS(df_graphs, file = "data/output/Study_3/df_graphs_S3.rds")

print("df_graphs_full is trial level dataset; df_graphs is trial level quantitative data only")

```



## Z-SCORED

Create duplicate versions of datasets used to analyze the semantic differential scores, with standardized (i.e. z-scored). Created as separate files rather than adding cols to extant dfs b/c it makes the looping graphing code more readable


```{r, standardizing-zscores}

########## Z-SCORE
## ON STANDARDIZATION
## https://cran.r-project.org/web/packages/datawizard/vignettes/standardize_data.html

## DF_GRAPHS_Z
## VARIABLE WISE STANDARDIZATION
df_graphs_z <- df_graphs %>% 
  mutate(
    PRE_DESIGN_z  = datawizard::standardize(PRE_DESIGN),
    PRE_DATA_z = datawizard::standardize(PRE_DATA),
    PRE_POLITICS_z = datawizard::standardize(PRE_POLITICS),
    PRE_TRUST_z = datawizard::standardize(PRE_TRUST),
    PRE_ALIGN_z = datawizard::standardize(PRE_ALIGN),
    PRE_BEAUTY_z = datawizard::standardize(PRE_BEAUTY),
    PRE_INTENT_z = datawizard::standardize(PRE_INTENT),
    PRE_LATENCY_z = datawizard::standardize(PRE_LATENCY),
    PRE_ID_CONF_z = datawizard::standardize(PRE_ID_CONF),
    PRE_AGE_CONF_z = datawizard::standardize(PRE_AGE_CONF),
    PRE_GENDER_CONF_z = datawizard::standardize(PRE_GENDER_CONF),
    POST_DESIGN_z  = datawizard::standardize(POST_DESIGN),
    POST_DATA_z = datawizard::standardize(POST_DATA),
    POST_POLITICS_z = datawizard::standardize(POST_POLITICS),
    POST_TRUST_z = datawizard::standardize(POST_TRUST),
    POST_ALIGN_z = datawizard::standardize(POST_ALIGN),
    POST_BEAUTY_z = datawizard::standardize(POST_BEAUTY),
    POST_INTENT_z = datawizard::standardize(POST_INTENT),
    POST_LATENCY_z = datawizard::standardize(POST_LATENCY),
    POST_ID_CONF_z = datawizard::standardize(POST_ID_CONF),
    POST_AGE_CONF_z = datawizard::standardize(POST_AGE_CONF),
    POST_GENDER_CONF_z = datawizard::standardize(POST_GENDER_CONF)
  )
write.csv(df_graphs_z, file = "data/output/Study_3/df_graphs_z_S3.csv", na="")
saveRDS(df_graphs_z, file = "data/output/Study_3/df_graphs_z_S3.rds")


## DF_SD_QUESTIONS_LONG_Z
## LONG DATAFRAME FOR RAINCLOUDS
df_sd_questions_long_z <- df_graphs_z %>% 
  #get rid of datawizard transform but save raw z-score values
  mutate(
    PRE_DESIGN_z = as.numeric(PRE_DESIGN_z),
    PRE_DATA_z = as.numeric(PRE_DATA_z),
    PRE_POLITICS_z = as.numeric(PRE_POLITICS_z),
    PRE_TRUST_z = as.numeric(PRE_TRUST_z),
    PRE_ALIGN_z = as.numeric(PRE_ALIGN_z),
    PRE_BEAUTY_z = as.numeric(PRE_BEAUTY_z),
    PRE_INTENT_z = as.numeric(PRE_INTENT_z),
    POST_DESIGN_z = as.numeric(POST_DESIGN_z),
    POST_DATA_z = as.numeric(POST_DATA_z),
    POST_POLITICS_z = as.numeric(POST_POLITICS_z),
    POST_TRUST_z = as.numeric(POST_TRUST_z),
    POST_ALIGN_z = as.numeric(POST_ALIGN_z),
    POST_BEAUTY_z = as.numeric(POST_BEAUTY_z),
    POST_INTENT_z = as.numeric(POST_INTENT_z),
  ) %>% 
#drop non z-scored columns AND confidence cols
  select(- (PRE_ENCOUNTER:POST_LATENCY), 
         - contains(c("_CONF", "_LATENCY"))) %>% 
  ## pivot longer the SD questions
  pivot_longer(
    cols = contains(ref_sd_questions_wide_z),
    names_to = "QUESTION", 
    values_to = c("value")
  ) %>%
  ## separate PRE and POST into time columns
  mutate(
    TIME = case_when(
      str_detect(QUESTION,"-P") ~"POST",
      !str_detect(QUESTION,"-P") ~"PRE"),
    QUESTION = str_replace_all(QUESTION,"PRE_",""),
    QUESTION = str_replace_all(QUESTION,"POST_","")
  ) %>% 
  mutate(
    TIME = factor(TIME, levels=order_times),
    QUESTION = factor(QUESTION, levels=ref_sd_questions_z)
  ) %>% droplevels()
write.csv(df_sd_questions_long_z, file = "data/output/Study_3/df_sd_questions_long_z_S3.csv", na="")
saveRDS(df_sd_questions_long_z, file = "data/output/Study_3/df_sd_questions_long_z_S3.rds")    

```

## ABSOLUTE_VALUE

```{r, standardizing-absvalue}

########## ABS VALUE
## COLLAPSE SD SCALES AT 0 TO SHOW MIDDLE VS EXTREMES

## DF_GRAPHS_ABS
## VARIABLE WISE STANDARDIZATION
df_graphs_abs <- df_graphs %>% 
  mutate(
    PRE_DESIGN = abs(PRE_DESIGN - 50),
    PRE_DATA = abs(PRE_DATA - 50),
    PRE_POLITICS = abs(PRE_POLITICS - 50),
    PRE_TRUST = abs(PRE_TRUST - 50),
    PRE_ALIGN = abs(PRE_ALIGN - 50),
    PRE_BEAUTY = abs(PRE_BEAUTY - 50),
    PRE_INTENT = abs(PRE_INTENT - 50),
    POST_DESIGN = abs(POST_DESIGN - 50),
    POST_DATA = abs(POST_DATA - 50),
    POST_POLITICS = abs(POST_POLITICS - 50),
    POST_TRUST = abs(POST_TRUST - 50),
    POST_ALIGN = abs(POST_ALIGN - 50),
    POST_BEAUTY = abs(POST_BEAUTY - 50),
    POST_INTENT = abs(POST_INTENT - 50)
  )
write.csv(df_graphs_abs, file = "data/output/Study_3/df_graphs_abs_S3.csv", na="")
saveRDS(df_graphs_abs, file = "data/output/Study_3/df_graphs_abs_S3.rds")



## DF_SD_QUESTIONS_LONG_Z
## LONG DATAFRAME FOR RAINCLOUDS
df_sd_questions_long_abs <- df_graphs_abs %>% 
  #get rid of datawizard transform but save raw z-score values
  select(PID:STIMULUS_CATEGORY,
         contains(ref_sd_questions_wide)) %>% 
  ## pivot longer the SD questions
  pivot_longer(
    cols = contains(ref_sd_questions_wide),
    names_to = "QUESTION", 
    values_to = c("value")
  )  %>% 
  mutate(
    TIME = case_when(
      str_detect(QUESTION,"POST_") ~"POST",
      !str_detect(QUESTION,"POST") ~"PRE"),
    QUESTION = str_replace_all(QUESTION,"PRE_",""),
    QUESTION = str_replace_all(QUESTION,"POST_","")
  )  %>% 
  mutate(
    TIME = factor(TIME, levels=order_times),
    QUESTION = factor(QUESTION, levels=ref_sd_questions)
  ) %>% droplevels()
write.csv(df_sd_questions_long_abs, file = "data/output/Study_3/df_sd_questions_long_abs_S3.csv", na="")
saveRDS(df_sd_questions_long_abs, file = "data/output/Study_3/df_sd_questions_long_abs_S3.rds")    

```

# PROFILING

## PARTICIPANT-LEVEL

```{r summarytools-profile-participants, results='asis'}


dfSummary(df_participants , #%>% select(PID, duration.min, Distribution, Assigned.Block, PLATFORM, 
                      #       contains("D_"), Prolific.Name:Study, contains("SCREEN_")), 
          headings = TRUE,
          plain.ascii  = FALSE,
          style        = 'grid',
          graph.magnif = 0.85,
          varnumbers = FALSE,
          valid.col    = FALSE,
          tmp.img.dir  = "/tmp")


```

## TRIAL-LEVEL

```{r summarytools-profile-graphs, results='asis'}


dfSummary(df_graphs,  # %>% select(PID, duration.min, Distribution, Assigned.Block, PLATFORM,
                      #       contains("D_"), Prolific.Name:Study, contains("SCREEN_")), 
          headings = TRUE,
          plain.ascii  = FALSE,
          style        = 'grid',
          graph.magnif = 0.85,
          varnumbers = FALSE,
          valid.col    = FALSE,
          tmp.img.dir  = "/tmp")


```

