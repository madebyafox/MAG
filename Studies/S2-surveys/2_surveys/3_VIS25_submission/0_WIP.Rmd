---
title: "WIP ANALYSIS"
author: "ANONYMIZED"
date: "2024-02-24"
output:
  html_document:
    theme: cosmo
    code_folding: hide
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 6
  pdf_document:
    toc: yes
    toc_depth: '5'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
editor_options: 
  markdown: 
    wrap: 72
---

# SETUP

### Import Packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(psych) #describe() & efa
library(tidyverse) #all the things
library(magrittr) #special pipes like %<>%
library(summarytools) #data quality
library(lubridate) #dealing with dates
library(tinytable) ##sparkline tables 
library(webshot2) ##saving sparkline tables

#EDA
library(qacBase)

#VIZ
library(ggformula) #regression syntax viz
library(ggstatsplot) #dummies
library(gghalves) #half boxplots 
library(GGally) #extends ggplot for EDA 
library(corrplot) #sophisticated correlation plots
library(ggeasy) #easy labelling
library(ggh4x) #guides [dual axes]
library(patchwork) #multi-plot layout
library(ggdist) #raincloud plots and other distributionals
library(viridis) #color palettes
library(RColorBrewer) #color palettes
library(plotly) # interactive graphs
library(paletteer) #more palettes
library(interactions) ##easier regression ixn plots.srlsy
library(tidygraph)

#MODELLING
library(jtools) #Social Science regression utilities
library(easystats) #modelling helpers
library(see)
library(sjPlot)
library(lme4)
library(lmerTest) #for CIs in glmer
# library(mixed) ## utilities for glmers 
library(jmv) ## jamovi EFA


#STATISTICAL TESTS 
library(kSamples) #AD K-SAMPLE TEST (for distribution comparison)
library(rstatix) #FRIEDMAN'S TESTS and effect sizes 

#CONFIG
options(readr.show_col_types = FALSE) #don't show coltypes on read_csv
n_blocks = 6

## IMPORTANT 
GRAPH_SAVE = TRUE #set to true to generate all the SD graphs and save to folders 
source("graphing_functions.R") #import graphing palettes and custom functions

```

### Import References

```{r import-refs, message=FALSE, warning = FALSE}

############## IMPORT REFERENCE FILES
ref_stimuli <- readRDS("data/input/REFERENCE/ref_stimuli.rds")
ref_labels <- readRDS("data/input/REFERENCE/ref_labels.rds")


############## SETUP Graph Labels
ref_stim_id <- levels(ref_stimuli$ID)
ref_cat_questions <- c("MAKER_ID","MAKER_AGE","MAKER_GENDER")
ref_free_response <- c("MAKER_DETAIL", "MAKER_EXPLAIN", "TOOL_DETAIL", "CHART_EXPLAIN")
ref_conf_questions <- c("MAKER_CONF", "AGE_CONF", "GENDER_CONF", "TOOL_CONF")
ref_sd_questions <- rownames(ref_labels)
ref_blocks <- c(1,2,3,4,5,6)


############## FULL QUESTION SET FOR S1_2
ref_sd_questions <- c("MAKER_DESIGN","MAKER_DATA",
                      "MAKER_POLITIC", "MAKER_ARGUE","MAKER_SELF","MAKER_ALIGN","MAKER_TRUST",
                      "CHART_TRUST", "CHART_INTENT", "CHART_LIKE", "CHART_BEAUTY")

ref_sd_questions_z <- c("MAKER_DESIGN_z","MAKER_DATA_z",
                      "MAKER_POLITIC_z", "MAKER_ARGUE_z","MAKER_SELF_z","MAKER_ALIGN_z","MAKER_TRUST_z",
                      "CHART_TRUST_z", "CHART_INTENT_z", "CHART_LIKE_z", "CHART_BEAUTY_z")


############## MINIMAL QUESTION SET FOR Study 3
ref_min_sd_questions <-  c("DESIGN","DATA","POLITICS", "TRUST","ALIGN","BEAUTY","INTENT")
ref_min_sd_questions_z <-  c("DESIGN_z","DATA_z","POLITICS_z", "TRUST_z","ALIGN_z","BEAUTY_z","INTENT_z")
ref_min_conf_questions <- c("ID_CONF","AGE_CONF","GENDER_CONF")
ref_min_cat_questions <- c("ENCOUNTER","ID","AGE","GENDER")
ref_min_free_questions <- c("EXPLAIN")





```

### Import Data

```{r import-data, message=FALSE, warning = FALSE}

############## IMPORT Study 1_3 DATA FILES
df_participants <- readRDS("data/output/Study_1_2/df_participants.rds") #1 row per participant — demographic
df_graphs <- readRDS("data/output/Study_1_2/df_graphs.rds") #only categorical and numeric questions
df_graphs_z <- readRDS("data/output/Study_1_2/df_graphs_z.rds") #only categorical and numeric questions
df_sd_questions_long <- readRDS("data/output/Study_1_2/df_sd_questions_long.rds") # only sd questions LONG


############## IMPORT Study 3 DATA FILES
df_questions_s3 <- readRDS("data/output/Study_3/df_questions_S3.rds")
df_graphs_s3 <- readRDS("data/output/Study_3/df_graphs_s3.rds") #only categorical and numeric questions
df_graphs_z_s3 <- readRDS("data/output/Study_3/df_graphs_z_s3.rds") #only categorical and numeric questions

############## IMPORT COMBINED DATA FILES
df_graphs_all <- readRDS("data/output/COMBINED/df_graphs_ALL.rds")

```

# NEW

## [1] EFA

```{r}
print("DATA AVAILABLE WITH FULL QUESTION SET")
table(df_graphs$Study, df_graphs$Assigned.Block)

print("DATA AVAILABLE WITH REDUCED QUESTION SET")
table(df_graphs_all$Study, df_graphs_all$Assigned.Block)
```

**PRE-REQUISISITES**

1.  **Bartlett’s Test of Sphericity:** Tests if the correlation matrix
    is significantly different from an identity matrix (no
    correlations). p \< 0.05 indicates sufficient correlations.

2.  **Kaiser-Meyer-Olkin (KMO) Measure:** Assesses sampling adequacy for
    EFA (overall and per variable). Overall KMO ≥ 0.60 is acceptable.
    KMO ≥ 0.80 is meritorious. Variables with KMO \< 0.50 might need
    removal.

**OUTCOMES**

1.  **FACTOR LOADINGS**: Factor loadings represent the correlation
    between each variable and a factor.

    -   Higher absolute loadings indicate stronger relationships between
        the item and the factor.

    -   ≥ 0.70 Very strong loading (ideal, but rare in practice).

    -   0.50 – 0.70 Moderate to strong—good indicator of factor
        membership.

    -   0.30 – 0.50 Weak to moderate—may be acceptable depending on
        context and theory.

    -   \< 0.30 Weak—often considered too low to retain, unless
        justified theoretically.

2.  **COMMUNALITY** (h\^2) H2: indicates the proportion of variance in a
    variable that is explained by the extracted factors.

    -   It ranges from 0 to 1 (or 0% to 100% if expressed as a
        percentage). Think of it as shared variance: how much of a
        variable's variance is accounted for by the common factors.

    -    ≥ 0.60 Excellent—variable is well explained by the factors.

    -   0.40 – 0.60 Acceptable in many cases, especially in social
        sciences.

    -   \< 0.40 Low—variable may not fit well in the factor model.
        Consider revising or dropping it (but consider theory first).

3.  **UNIQUENESS** (u²): U2: Proportion of variance unique to the
    variable, not explained by factors.

4.  **COMPLEXITY**: Complexity (com) measures how many factors a
    variable meaningfully loads onto.com Value Meaning

    -   1.0 The variable loads strongly on one factor (simple
        structure).

    -   \> 1.0 The variable loads on multiple factors, with complexity
        increasing as it spreads across more factors.

    -   Higher values (e.g., 1.5–2.5) The variable is cross-loading
        across factors, making interpretation harder.

**SUMMARY**

-   Factor Loadings: Ideally ≥ 0.50 on one factor and low on the others.
-   Communalities (H2): Ideally ≥ 0.40 for most items.
-   Cross-loadings: Avoid or minimize; interpret with caution.
-   Theoretical Coherence: Even if a loading is statistically "low,"
    theory may justify its retention.

### (1) EFA : REDUCED VARS

#### (1.1) EFA : REDUCED VARS : S1, S2, S3, S4(PRE) (UNBALANCED BLOCKS)

```{r}

## SETUP DATA
df <- df_graphs_all%>% select(all_of(ref_min_sd_questions_z))
x <- ref_min_sd_questions_z


## RUN EFA JAMOVI STYLE
jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)


## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

```

#### !!! (1.2) EFA : REDUCED VARS : S1, S2 (BALANCED BLOCKS)

```{r}

## SETUP DATA
df <- df_graphs_all%>% filter(Study %in% c("Study1","Study2"))
table(df$Study, df$Assigned.Block)
x <- ref_min_sd_questions_z

## RUN EFA JAMOVI STYLE
(ef <- jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)
)

## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

## SAVE EFA
saveRDS(ef, file = "models/EFA_S1_S2_minimal.rds")

```

### (2) EFA : FULL VARS

#### (2.1) EFA : FULL VARS : S1,S2 (BALANCED BLOCKS)

```{r}

## SETUP DATA
df <- df_graphs_z%>% filter(Study %in% c("Study1","Study2"))
table(df$Study, df$Assigned.Block)
x <- ref_sd_questions_z
print(x)

## RUN EFA JAMOVI STYLE
jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)


## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

```

## [2] MODELLING TRUST

#### SETUP MODEL DATA (S1,S3 balanced)

```{r hypo-trust_beauty_intent-data}

df <- df_graphs_all %>% 
  # filter only Study 1 and 2
  filter(Study %nin% c("Study0","Study3"))
print("Data in Model")
table(df$Study, df$Assigned.Block)


# # df <- df_graphs %>%
#   ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
#   # filter(STIMULUS != "B0-0") %>% 
#   select(PID, STIMULUS,STIMULUS_CATEGORY, MAKER_ID, MAKER_TRUST, CHART_TRUST, CHART_BEAUTY, CHART_INTENT, MAKER_DATA) %>% 
#   mutate(
#     TRUST_Z = datawizard::standardise(CHART_TRUST),
#     BEAUTY_Z = datawizard::standardise(CHART_BEAUTY),
#     INTENT_Z = datawizard::standardise(CHART_INTENT),
#     DATA_Z = datawizard::standardise(MAKER_DATA)
#   ) %>% 
#   droplevels()
```

#### M1 \| TRUST \~ BEAUTY

We begin by fitting a linear mixed effects, model predicting
`CHART_TRUST` by `CHART_BEAUTY` to see whether our data support the
claims made by Lin & Thorton, 2021.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

```{r, m1}

################## FIT MODEL
f.B <-  "TRUST ~ BEAUTY + (1|PID)"
mm.B <- lmer(TRUST_z ~ BEAUTY_z + (1|PID), data = df)
summary(mm.B)
car::Anova(mm.B, type=2)
performance(mm.B)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.B, type = "est", show.intercept = TRUE,show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.B, type = "pred", terms = "BEAUTY_z") +  theme_minimal()
(g <- (e+p) + plot_annotation(title = f.B))


```

A model predicting `TRUST` by `BEAUTY` explains 22% variance in
`CHART_TRUST`, with 12% variance explained by a significant main effect
of `BEAUTY` ($t(1548) = 15.30, p <
.001$). The model coefficient indicates that for every 1 standard
deviation increase in `BEAUTY`, `CHART-TRUST` increases on average by
0.35 SD.

**Model 1 supports the argument of Lin & Thorton (2021) that graphs
judged to be more attractive are also judged as more trustworthy.**


#### M2 \| TRUST \~ BEAUTY + INTENT

Here we add a main effect term `INTENT` as a predictor to the previous
model and compare fit with Model 1, to determine whether a social
attribution (in this case inference about the maker's intent) is also
predictive of `TRUST`.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

```{r m2}

################## FIT MODEL
f.BI <-  "TRUST ~ BEAUTY + INTENT + (1|PID)"
mm.BI <- lmer(TRUST_z ~ BEAUTY_z + INTENT_z + (1|PID), data = df)
summary(mm.BI)
car::Anova(mm.BI, type=2)

################## COMPARE MODEL
compare_performance(mm.BI, mm.B, rank = TRUE)
anova(mm.BI, mm.B)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BI, type = "est", show.intercept = TRUE,show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BI, type = "pred", terms = c("BEAUTY_z", "INTENT_z")) + theme_minimal()
(g <- (e+p) + plot_annotation(title = f.B, caption="low intent = inform, high intent = persuade"))


################## ALT PLOTS
plot_model(mm.BI, type = "pred", terms = c("BEAUTY_z", "INTENT_z")) + theme_minimal()
plot_model(mm.BI, type = "pred", terms = c("INTENT_z","BEAUTY_z")) + theme_minimal()
```

A model predicting `TRUST` by a linear combination of `BEAUTY` and
`INTENT` explains 38% variance in `TRUST`, with 28% variance explained
by fixed effects alone:

1.  A significant main effect of `BEAUTY` ($t(1540) = 14.62, p <.001$),
    and

2.  A significant main effect of `INTENT` ($t(1584) = -18.97, p <.001$).

    The model coefficients indicates that for every 1 standard deviation
    increase in `BEAUTY`, `TRUST` increases on average by 0.3 SD (more
    beauty corresponds to more trust). For every 1 standard deviation
    increase in `INTENT`, (where LOW values correspond to intent to
    INFORM and high values correspond to intent to PERSUADE) `TRUST`
    decreases by 0.4 SD (more persuasive corresponds to less
    trustworthy).

Further, model comparisons indicate that MODEL 2 (including
`CHART_INTENT`) is a significantly better fit to the data
($\chi^2(1) = 324 , p < 0.001$) than MODEL 1 including `BEAUTY` alone.

**Model 2 supports our claim that social attributions (in this case, an
inference about the communicative intent of the chart) *also* predict
beauty, above and beyond the beauty-centric argument of Lin & Thorton
(2021) that graphs judged to be more attractive are also judged as more
trustworthy.**

#### M3 \| TRUST \~ BEAUTY X INTENT

Here we fit a model with `INTENT` as an **interaction** with `BEAUTY`,
and compare with the previous model (with the simple linear combination
of the two predictors) to determine whether simply affecting `TRUST`,
the social attribution of `INTENT` **moderates** the effect of `BEAUTY`
on `TRUST`.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

```{r m3}

################## FIT MODEL
f.BxI <-  "TRUST ~ BEAUTY X INTENT + (1|PID)"
mm.BxI <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + (1|PID), data = df)
summary(mm.BxI)
car::Anova(mm.BxI, type=3)  #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxI, mm.BI, rank = TRUE)
anova(mm.BxI, mm.BI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxI, type = "est", show.intercept = TRUE,show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BxI, type = "int", terms = c("INTENT_z","BEAUTY_z"),mdrt.values = "all") + theme_minimal()
(g <- (e+p) + plot_annotation(title = f.BxI, caption="low intent = inform, high intent = persuade", subtitle = f.BxI))


################## ALT PLOTS
plot_model(mm.BxI, type = "pred", terms = c("BEAUTY_z", "INTENT_z")) + theme_minimal()
plot_model(mm.BxI, type = "pred", terms = c("INTENT_z","BEAUTY_z")) + theme_minimal()

```

A model predicting `CHART-TRUST` by a linear **interaction** of
`CHART_BEAUTY` and `CHART_INTENT` explains 40% variance in
`CHART_TRUST`, with 30% variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 210, p <.001$)

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 338, p <.001$)

3.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 35, p <.001$)

    The model coefficients indicates that for every 1 standard deviation
    increase in `CHART-BEAUTY`, `CHART-TRUST` increases on average by
    0.3 SD (more beauty corresponds to more trust). For every 1 standard
    deviation increase in `CHART_INTENT`, (where LOW values correspond
    to intent to INFORM and high values correspond to intent to
    PERSUADE) `CHART-TRUST` decreases on average by 0.4 SD (more
    persuasive corresponds to less trust). The significant interaction
    term indicates the difference in slope between the two main effects,
    that is to say, that the effect of `CHART_BEAUTY` on `CHART_TRUST`
    is **moderated** such that the effect of `CHART_BEAUTY` is
    *minimized* when `CHART_INTENT` is attributed as more informative
    (lower values of chart_intent) than persuasive (higher values of
    chart_intent) (Trust increases as a function of beauty MORE for more
    persuasive intents. The difference in trust for unattractive and
    attractive images intended to inform is lower. )

Further, model comparisons indicate that MODEL 3 (an interaction rather
than MODEL 2 with a linear combination of `CHART_BEAUTY` and
`CHART_INTENT`) is a significantly better fit to the data
($\chi^2(1)=34.81 , p < 0.001$).

**Model 3 supports our claim that social attributions (in this case, an
inference about the communicative intent of the chart) *also* predict
beauty, and in fact can change (moderate) the effect of beauty on
trust.**

#### M4 \| TRUST \~ BEAUTY X INTENT + DATA

Here we add `MAKER_DATA` competency to our previous model to determine
whether a viewer's inferences about the data analysis ability of the
chart's maker affect assesments of the chart's trustworthiness.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

-   (`MAKER_DATA` 0 = *professional* in data analysis , 100 =
    *layperson* in data analysis)

```{r, m4}

################## FIT MODEL
f.BxID <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.BxID <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.BxID)
car::Anova(mm.BxID, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxID, mm.BxI, rank = TRUE)
anova(mm.BxID, mm.BxI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxID, type = "est", show.intercept = TRUE,show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BxID, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))


################## ALT PLOTS
# plot_model(mm.BxID, type = "pred", terms = c("BEAUTY_z", "INTENT_z","DATA_z")) + theme_minimal()
# plot_model(mm.BxID, type = "pred", terms = c("INTENT_z","BEAUTY_z","DATA_z")) + theme_minimal()
plot_model(mm.BxID, type = "pred", terms = c("INTENT_z","DATA_z","BEAUTY_z")) + theme_minimal()

```

A model predicting `CHART-TRUST` by a linear **interaction** of
`CHART_BEAUTY` and `CHART_INTENT` as well as a main effect of
`MAKER_DATA` competency explains 41% variance in `CHART_TRUST`, with 32%
variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 175, p <.001$)

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 243, p <.001$)

3.  A significant main effect of `MAKER_DATA`
    ($\chi^2(1) = 57, p <.001$)

4.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 31, p <.001$)

    The model coefficients indicates that for every 1 standard deviation
    increase in `MAKER_DATA`, `CHART-TRUST` decreases on average by 0.16
    SD (less expertise/more layperson corresponds to lower trust). For
    every 1 standard deviation increase in `CHART-BEAUTY`, `CHART-TRUST`
    increases on average by 0.3 SD (more beauty corresponds to more
    trust). For every 1 standard deviation increase in `CHART_INTENT`,
    (where LOW values correspond to intent to INFORM and high values
    correspond to intent to PERSUADE) `CHART-TRUST` decreases on average
    by 0.3 SD ( persuasive corresponds to less trust; informative
    corresponds to more trust). The significant interaction term
    indicates the difference in slope between the main effects for
    `CHART_BEAUTY` and `CHART_INTENT`, that is to say, that the effect
    of `CHART_BEAUTY` on `CHART_TRUST` is **moderated** such that the
    effect of `CHART_BEAUTY` is *minimized* when `CHART_INTENT` is
    attributed as more informative (lower values on chart_intent) than
    persuasive (higher values on chart_intent)

Further, model comparisons indicate that MODEL 4 (adding a simple main
effect of `MAKER_DATA`) is a significantly better fit to the data than
MODEL 3 without the `MAKER_DATA` fixed effect
($\chi^2(1)=56.4 , p < 0.001$) .

**Model 4 supports our claim that social attributions (in this case,
*both* an inference about the communicative intent of the chart and
inference about the data analysis skill of the maker) *also* predict
beauty, and in fact can change (in the case of intent, moderate) the
effect of beauty on trust.**

#### M5 \| TRUST \~ BEAUTY X INTENT X DATA

Here we add an interaction with `MAKER_DATA` competency to our previous
model to determine whether a viewer's inferences about the data analysis
ability of the chart's maker MODERATE the effects of INTENT and BEAUTY
on assesments of trustworthiness.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

-   (`MAKER_DATA` 0 = *professional* in data analysis , 100 =
    *layperson* in data analysis)

```{r, m5}

################## FIT MODEL
f.BxIxD <-  "TRUST ~ BEAUTY X INTENT X DATA (1|PID)"
mm.BxIxD <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z * DATA_z + (1|PID), data = df)
summary(mm.BxIxD)
car::Anova(mm.BxIxD, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIxD, mm.BxID, rank = TRUE)
anova(mm.BxIxD, mm.BxID)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxIxD, type = "est", show.intercept = TRUE, show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BxIxD, type = "pred", terms = c("BEAUTY_z","INTENT_z", "DATA_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxIxD))


################## ALT PLOTS
plot_model(mm.BxIxD, type = "pred", terms = c("INTENT_z", "BEAUTY_z")) + theme_minimal() + labs(subtitle ="sig ixn beauty x intent")
plot_model(mm.BxIxD, type = "pred", terms = c("INTENT_z", "DATA_z")) + theme_minimal() + labs(subtitle ="sig ixn data x intent")
plot_model(mm.BxIxD, type = "pred", terms = c("BEAUTY_z", "DATA_z")) + theme_minimal() + labs(subtitle ="NO IXN BEAUTY x DATA")
plot_model(mm.BxIxD, type = "pred", terms = c("BEAUTY_z","DATA_z", "INTENT_z")) + theme_minimal()
```

Here we see that the three-way interaction between BEAUTY X INTENT X
DATA is not statistically significant. ($\chi^2(1) = 1.4, p =0.24$).
There is a significant 2-way interaction between INTENT & DATA, such
that increased DATA competency (low data values) lessen the effect of
intent on trust. However there is NOT a significant interaction between
DATA and BEAUTY (the maker's skill in data analysis does not affect the
relationship between beauty and trust)

The more complicated model is not a significantly better fit, and so we
keep the simpler model (no three-way interaction).
($\chi^2(3)=5.13 , p = 0.16$) .

#### M6 \| TRUST \~ BEAUTY X INTENT + DATA + ALIGN

Here we add a main effect of `ALIGNMENT` to our previous model to
determine whether a viewer's attitudes about how the maker's values
align with their own affect assesments of trustworthiness.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

-   (`MAKER_DATA` 0 = *professional* in data analysis , 100 =
    *layperson* in data analysis)

-   (`ALIGN` 0 = *does NOTshare* my values , 100 = *DOES SHARE* my
    values)

```{r, m6}

################## FIT MODEL
f.BxIDA <-  "TRUST ~ BEAUTY X INTENT + DATA + ALIGN (1|PID)"
mm.BxIDA <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + ALIGN_z + (1|PID), data = df)
summary(mm.BxIDA)
car::Anova(mm.BxIDA, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIDA, mm.BxID, rank = TRUE)
anova(mm.BxIDA, mm.BxID)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxIDA, type = "est", show.intercept = TRUE, show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p1 <- plot_model(mm.BxIDA, type = "pred", terms = c("BEAUTY_z","INTENT_z")) + theme_minimal()
p2 <- plot_model(mm.BxIDA, type = "pred", terms = c("DATA_z","ALIGN_z")) + theme_minimal()
(g <- (e/p1/p2) + plot_annotation(title = f.BxIDA, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxIDA))



## see each two-way interaction
# plot_model(mm.BxIxD, type = "pred", terms = c("INTENT_z", "BEAUTY_z")) + theme_minimal() + labs(subtitle ="sig ixn beauty x intent")
# plot_model(mm.BxIxD, type = "pred", terms = c("INTENT_z", "DATA_z")) + theme_minimal() + labs(subtitle ="sig ixn data x intent")
# plot_model(mm.BxIxD, type = "pred", terms = c("BEAUTY_z", "DATA_z")) + theme_minimal() + labs(subtitle ="NO IXN BEAUTY x DATA")

```

A model predicting `CHART-TRUST` by a linear combination of maker
`ALIGN`ment with `DATA` competency and an **interaction** of
`CHART_BEAUTY` and `CHART_INTENT` as explains 58% variance in
`CHART_TRUST`, with 51% variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 34, p <.001$)

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 152, p <.001$)

3.  A significant main effect of `MAKER_DATA`
    ($\chi^2(1) = 80, p <.001$)

4.  A significant main effect of `MAKER_ALIGN`
    ($\chi^2(1) = 628, p <.001$)

5.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 31, p <.001$)

    The model standardized beta coefficients indicates that for every 1
    standard deviation increase `MAKER_DATA` (more layperson, less
    professional), `CHART-TRUST` decreases on average by 0.17 SD (less
    professional corresponds with less trust). For every in 1 standard
    deviation increase in `MAKER_ALIGN` (more values shared)
    `CHART-TRUST` increases on average by 0.5 SD (more alignment
    corresponds with more trust). For every 1 standard deviation
    increase in `CHART_INTENT`, (where LOW values correspond to intent
    to INFORM and high values correspond to intent to PERSUADE)
    `CHART-TRUST` decreases on average by 0.23 SD ( persuasive
    corresponds to less trust; informative corresponds to more trust).
    And for every in 1 standard deviation increase in `CHART_BEAUTY`
    trustworthiness increases by 0.2 SD on average. The significant
    interaction term indicates the difference in slope between the main
    effects for `CHART_BEAUTY` and `CHART_INTENT`, that is to say, that
    the effect of `CHART_BEAUTY` on `CHART_TRUST` is **moderated** such
    that the effect of `CHART_BEAUTY` is *minimized* when `CHART_INTENT`
    is attributed as more informative (lower values on chart_intent)
    than persuasive (higher values on chart_intent)

Further, model comparisons indicate that MODEL 6 (adding a simple main
effect of `MAKER_ALIGN`) is a significantly better fit to the data than
MODEL 4 without the fixed effect ($\chi^2(1)= 529 , p < 0.001$) .

**Model 6 supports our claim that social attributions (in this case,
*both* an inference about the communicative intent of the chart and
inference about the data analysis skill of the maker and the extent to
which the maker's values align with the participants') *also* predict
beauty, and in fact can change (in the case of intent, moderate) the
effect of beauty on trust.**

#### M7 \| TRUST \~ BEAUTY X INTENT + INTENT X ALIGN + DATA

TL;DR:

1.  **ALIGNMENT moderates INTENT** (more alignment mitigates differences
    in trust based on intent; the more aligned the values are the less
    difference there is in trust based on intent to inform vs. to
    persuade) 2.

2.  **INTENT moderates BEAUTY** (more beauty mitigates differences in
    trust based on intent; the more beautiful the less difference there
    is in trust based on intent to inform or persuade)

3.  **MAIN EFFECT DATA** (less professional =\> less trustworthy)

4.  **MAIN EFFECT INTENT** (more persuasive =\> less trustworthy)

5.  **MAIN EFFECT ALIGNMENT** (more aligned =\> more trustworthy)

6.  **MAIN EFFECT BEAUTY** (more beautify =\> more trustworthy)

Here we add `ALIGNMENT` as an interaction term to our previous model to
determine whether a viewer's attitudes about how the maker's values
align with their own might moderate the effects of intent and beauty on
assesments of trustworthiness.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

-   (`MAKER_DATA` 0 = *professional* in data analysis , 100 =
    *layperson* in data analysis)

-   (`ALIGN` 0 = *does NOTshare* my values , 100 = *DOES SHARE* my
    values)

```{r, m7}

################## FIT MODEL
f.BxIxAD <-  "TRUST ~ BEAUTY X INTENT + INTENT X ALIGN + DATA + (1|PID)"
mm.BxIxAD <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + INTENT_z*ALIGN_z + DATA_z + (1|PID), data = df)
summary(mm.BxIxAD)
car::Anova(mm.BxIxAD, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIxAD, mm.BxIDA, mm.BxID, rank = TRUE)
anova(mm.BxIxAD, mm.BxIDA)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxIxAD, type = "est", show.intercept = TRUE, show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p1 <- plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z","INTENT_z","DATA_z")) + theme_minimal()
p2 <- plot_model(mm.BxIxAD, type = "pred", terms = c("ALIGN_z","INTENT_z","DATA_z")) + theme_minimal()
(g <- (e/p1/p2) + plot_annotation(title = f.BxIxAD, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxIxAD))



## see each two-way interaction
print("two-way interaction")
plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "INTENT_z")) + theme_minimal() + labs(subtitle ="sig ixn intent x beauty", caption="INTENT matters MORE less beautiful")
plot_model(mm.BxIxAD, type = "pred", terms = c("ALIGN_z", "INTENT_z")) + theme_minimal() + labs(subtitle ="sig ixn intent align")
                                                                                                
plot_model(mm.BxIxAD, type = "pred", terms = c("INTENT_z","ALIGN_z")) + theme_minimal() 

plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "ALIGN_z")) + theme_minimal() + labs(subtitle ="NO IXN beauty align", caption = "MAIN EFFECT ALIGN; more aligned more trustworthy")
plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "DATA_z")) + theme_minimal() + labs(subtitle ="MAIN EFFECT DATA", caption = "MAIN EFFECT DATA; more professional = more trustworthy")

## plot all combinations
plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z","INTENT_z","ALIGN_z")) + theme_minimal() # facet align
plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z")) + theme_minimal() # facet intent

plot_model(mm.BxIxAD, type = "pred", terms = c("ALIGN_z","INTENT_z","BEAUTY_z")) + theme_minimal() # facet intent
plot_model(mm.BxIxAD, type = "pred", terms = c("ALIGN_z","BEAUTY_z","INTENT_z")) + theme_minimal() # facet intent

plot_model(mm.BxIxAD, type = "pred", terms = c("INTENT_z","BEAUTY_z","ALIGN_z")) + theme_minimal() # facet intent
plot_model(mm.BxIxAD, type = "pred", terms = c("INTENT_z","ALIGN_z","BEAUTY_z")) + theme_minimal() # facet intent



### PLOT WITH DATA EFFECT 
plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z","INTENT_z","ALIGN_z","DATA_z")) + theme_minimal() # facet align

plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z","DATA_z")) + theme_minimal() # facet intent

f.best <- f.BxIxAD
m.best <- mm.BxIxAD

```

TODO INTERPRETATION 
A model predicting `CHART-TRUST` explains 59% variance in `CHART_TRUST`,
with 51% variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 34, p <.001$) For every in 1 standard deviation
    increase in `CHART_BEAUTY` trustworthiness increases by 0.1 SD on
    average.

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 146, p <.001$). For every 1 standard deviation
    increase in `CHART_INTENT`, (where LOW values correspond to intent
    to INFORM and high values correspond to intent to PERSUADE)
    `CHART-TRUST` decreases on average by 0.23 SD ( persuasive
    corresponds to less trust; informative corresponds to more trust).

3.  A significant main effect of `MAKER_ALIGN`
    ($\chi^2(1) = 578, p <.001$). For every in 1 standard deviation
    increase in `MAKER_ALIGN` (more values shared) `CHART-TRUST`
    increases on average by 0.5 SD (more alignment corresponds with more
    trust).

4.  A significant main effect of `MAKER_DATA`
    ($\chi^2(1) = 81, p <.001$). The model standardized beta
    coefficients indicates that for every 1 standard deviation increase
    `MAKER_DATA` (more layperson, less professional), `CHART-TRUST`
    decreases on average by 0.17 SD (less professional corresponds with
    less trust).

5.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 31, p <.001$). The significant interaction term
    indicates the difference in slope between the main effects for
    `CHART_BEAUTY` and `CHART_INTENT`, that is to say, that the effect
    of `CHART_BEAUTY` on `CHART_TRUST` is **moderated** such that the
    effect of `CHART_BEAUTY` is *minimized* when `CHART_INTENT` is
    attributed as more informative (lower values on chart_intent) than
    persuasive (higher values on chart_intent)

6.  A significant interaction between `CHART_INTENT` and `CHART_ALIGN`
    ($\chi^2(1) = 31, p <.001$) The significant interaction term
    indicates that the difference in slope between the main effects for
    `CHART_INTENT` and `MAKER_ALIGN`, that is to say that the effect of
    intent on trust is moderated such that the effect of intent on trust
    is minimized the the more aligned a viewer feels with the maker. For
    less alignment, there is a greater difference in trust for
    persuasive vs. informative images; when the alignment is high, the
    trustworthiness of persuasive and informative images converge.

    The significant interaction term indicates the difference in slope
    between the main effects for `CHART_BEAUTY` and `CHART_INTENT`, that
    is to say, that the effect of `CHART_BEAUTY` on `CHART_TRUST` is
    **moderated** such that the effect of `CHART_BEAUTY` is *minimized*
    when `CHART_INTENT` is attributed as more informative (lower values
    on chart_intent) than persuasive (higher values on chart_intent)

Further, model comparisons indicate that MODEL 6 (adding a simple main
effect of `MAKER_ALIGN`) is a significantly better fit to the data than
MODEL 4 without the fixed effect ($\chi^2(1)= 529 , p < 0.001$) .

**Model 7 supports our claim that social attributions (in this case,
*both* an inference about the communicative intent of the chart and
inference about the data analysis skill of the maker and the extent to
which the maker's values align with the participants') *also* predict
beauty, and in fact can change (in the case of intent, moderate) the
effect of beauty on trust.**




#### M8 \| TRUST \~ BEAUTY X INTENT + INTENT X ALIGN (REMOVE DATA)

HERE we test whether we really actually need the DATA main effect 

```{r, m8}

################## FIT MODEL
f.BxIxA <-  "TRUST ~ BEAUTY X INTENT + INTENT X ALIGN + (1|PID)"
mm.BxIxA <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + INTENT_z * ALIGN_z + (1|PID), data = df)
summary(mm.BxIxA)
car::Anova(mm.BxIxA, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIxA, mm.BxIxAD, rank = TRUE)
anova(mm.BxIxA, mm.BxIxAD)

```

Yes, model 7 is better


#### M9 \| TRUST \~ BEAUTY X INTENT + INTENT X ALIGN + DATA+ MAKER_ID

HERE we test whether the MAKER_ID is predictive

```{r, m9}

################## FIT MODEL
f.BxIxADM <-  "TRUST ~ BEAUTY X INTENT + INTENT X ALIGN + DATA + MAKER + (1|PID)"
mm.BxIxADM <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + INTENT_z * ALIGN_z + DATA_z + ID + (1|PID), data = df)
summary(mm.BxIxADM)
car::Anova(mm.BxIxADM, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIxADM, mm.BxIxAD, rank = TRUE)
anova(mm.BxIxADM, mm.BxIxAD)

## TWO TERMS
print("two-way interaction")
plot_model(mm.BxIxADM, type = "pred", terms = c("ID","BEAUTY_z")) + theme_minimal() 
plot_model(mm.BxIxADM, type = "pred", terms = c("ID", "ALIGN_z")) + theme_minimal()
plot_model(mm.BxIxADM, type = "pred", terms = c("ID","INTENT_z")) + theme_minimal() 
plot_model(mm.BxIxADM, type = "pred", terms = c("ID","DATA_z")) + theme_minimal() 



## THREE TERMS
plot_model(mm.BxIxADM, type = "pred", terms = c("BEAUTY_z","INTENT_z","ID","ALIGN_z")) + theme_minimal() # facet align


```

#### M10 (FIGURE OUT MAKER) \| TRUST \~ BEAUTY BEAUTY * INTENT + INTENT*ALIGN + DATA + (1|PID)

```{r, m10}


################## FIT MODEL
f.BI.IA.AM.D <-  "TRUST ~ BEAUTY X INTENT + INTENT X ALIGN + ALIGN*MAKER + DATA + (1|PID)"
mm.BI.IA.AM.D <- lmer(TRUST_z ~ BEAUTY_z *INTENT_z + INTENT_z * ALIGN_z + ALIGN_z*ID + DATA_z + (1|PID), data = df)
summary(mm.BI.IA.AM.D)
car::Anova(mm.BI.IA.AM.D, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxIxADM, mm.BI.IA.AM.D, rank = TRUE)
anova(mm.BxIxADM, mm.BI.IA.AM.D)

## TWO TERMS
print("two-way interaction")
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("ID","BEAUTY_z")) + theme_minimal() + labs(title = f.BI.IA.AM.D)
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("ID", "ALIGN_z")) + theme_minimal()+ labs(title = f.BI.IA.AM.D)
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("ALIGN_z","ID")) + theme_minimal()+ labs(title = f.BI.IA.AM.D)
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("ID","INTENT_z")) + theme_minimal() + labs(title = f.BI.IA.AM.D)
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("ID","DATA_z")) + theme_minimal() + labs(title = f.BI.IA.AM.D)



## THREE TERMS
plot_model(mm.BI.IA.AM.D, type = "pred", terms = c("BEAUTY_z","ID","ALIGN_z")) + theme_minimal() + labs(title = f.BI.IA.AM.D)

## plot this with the raw data 
df %>% ggplot(aes(x=ALIGN_z, y= TRUST_z, color = ID))  + 
  geom_point() + 
  facet_wrap(~ID) + 
  geom_line(stat="lm")

```
- MAKER_ID not sign ixn w/ beauty
- MAKER_ID not sign ixn w/ intent
- MAKER_ID D yes SIG ixn w/ align
- TECHNICALLY THE ALIGN*MAKER is a sig better fit BUT this model is far too complicated to report AND it is only explains a miniscule amount more variance

#### M11 \| TRUST \~ BEAUTY * MAKER 

```{r, m11}

################## FIT MODEL
f.BxM <-  "TRUST_z ~ BEAUTY_z * ID + (1|PID)"
mm.BxM <- lmer(TRUST_z ~ BEAUTY_z * ID + (1|PID), data = df)
summary(mm.BxM)
car::Anova(mm.BxM, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxM, mm.BxMxIxAD, rank = TRUE)
anova(mm.BxM, mm.BxMxIxAD)

## TWO TERMS
print("two-way interaction")
plot_model(mm.BxM, type = "pred", terms = c("ID","BEAUTY_z")) + theme_minimal() + labs(title = f.BxM)

```
BEAUTY DOES INTERACT WITH MAKER (ALONE)
#### RE-RUN THIS PARTIAL R2 ANALYSIS with new best model



- I explored means-centering vs. z-scoring, as well as running the model on the original response scales, and demonstrated that the plots are the same (as expected) and z-scoring makes the coefficients interpretable as 1SD difference and main effects as value of that variable when all other vars are held at their mean



#### TODO MAIN FIGURE (FIG 9) Predicting Trust

**Here we produce the visualization and model parameters table reported
in Figure 9.**

```{r best-fit-model}

## SET BEST MODEL
m.best <- mm.BxIxAD
f.best <- f.BxIxAD
name="BxIxAD"

## SAVE BEST MODEL
saveRDS(m.best, file = paste0("models/TRUST_bestfit_","BxIxAD",".rds"))


################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
(e <- plot_model(best, type = "est", show.intercept = TRUE, show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal())
## PLOT MODEL PREDICTIONS
(p <- plot_model(best, type = "pred", terms = c("BEAUTY_z","INTENT_z","ALIGN_z")) + theme_minimal())
# (p <- plot_model(best, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z")) + theme_minimal())
plot_model(best, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z")) + theme_minimal()


## USE GGEFFECTS TO SIMPLIFY PLOT BY SPECIFYING WHICH VALUES OF THE CONTINUOUS VAR TO TAKE THE MARGINALS AT
# pred <- ggeffects::predict_response(best, terms = c("BEAUTY_z","ALIGN_z[-3,3]","INTENT_z","DATA_z[-2,2]"))
# plot(pred)




# plot_model(best, type = "pred", terms = c("ALIGN_z","INTENT_z","BEAUTY_z")) + theme_minimal()
# plot_model(best, type = "pred", terms = c("ALIGN_z","BEAUTY_z","INTENT_z")) + theme_minimal()

# plot_model(best, type = "pred", terms = c("BEAUTY_z","INTENT_z","ALIGN_z","DATA_z")) + theme_minimal()
# plot_model(best, type = "pred", terms = c("ALIGN_z","INTENT_z","BEAUTY_z","DATA_z")) + theme_minimal()
# 
# plot_model(best, type = "pred", terms = c("BEAUTY_z","INTENT_z","ALIGN_z")) + theme_minimal()
# plot_model(best, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z")) + theme_minimal()


# ## (1) BEAUTY X INTENT
plot_model(best, type = "pred", terms = c("BEAUTY_z","INTENT_z"),show.data=TRUE) + theme_minimal()
## (2) ALIGN X INTENT
plot_model(best, type = "pred", terms = c("ALIGN_z","INTENT_z")) + theme_minimal()
##  (3) MAIN EFFECTS
plot_model(best, type = "pred", terms = c("BEAUTY_z","ALIGN_z","INTENT_z")) + theme_minimal()

################## PLOT MODEL
g <- (e / p) + plot_annotation(title = f.best, caption="INTENT [inform <--> persuade] \n ALIGN[does NOT share <--> DOES share my values]")


################## PRINT MODEL TABLE
(t <- tab_model(best, file = "tab.html"))
# library(webshot)
webshot("tab.html", "figs/models/TRUST_model_table.png")
############
ggsave(plot= e, path="figs/models", filename = "TRUST_model_coefficients.png",units = c("in"), width = 8, height = 8,bg='#ffffff')
ggsave(plot = g, path="figs/models", filename =paste0("TRUST_model.png"), units = c("in"), width = 8, height = 10,bg='#ffffff'   )


##TODO LOOK INTO EMMEANS ??
## DECIDE WHICH PLOT CAN BE BEST ANNOTATED TO MAKE THE POINT
## ADD RAW DATA POINTS TO PLOT
## https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.html
```
### CALCULATE PARTIAL R2

```{r}
## <!-- https://chatgpt.com/c/67d6271c-15dc-800e-9e81-aa2b07a84d52 -->

## CAUTION THIS TAKES A VERY LONG TIME TO RUN (5H even on 4 cores?)

# # install.packages("partR2")
# library(partR2)
# library(future)
# library(furrr)
# # 
# # ## setup multiple cores to 
# plan(multisession, workers = 4)
# # 
# # # Mixed model
# model <- m.best
# 
# ######## GROUP PREDICTORS
# 
# # run Partial R2
# result <- partR2(
#   model,
#   partbatch = list(
#     "BEAUTY" = "BEAUTY_z",
#     "ALIGN" = "ALIGN_z",
#     "INTENT" = "INTENT_z",
#     "DATA" = "DATA_z",
#     "BEAUTY:INTENT" = "BEAUTY_z:INTENT_z",
#     "ALIGN:INTENT" = "INTENT_z:ALIGN_z"
#   ),
#   nboot = 1000
# )

# Print
# summary(result, sort = TRUE)
# saveRDS(result, file = "models/TRUST_bestfit_mm.BxIxAD_partR2.rds")


## LOAD PARTIAL R ANALYSIS 
# partialR <- readRDS("models/TRUST_bestfit_mm.BxIxAD_partR2.rds") # only sd questions LONG
# Print
# summary(partialR, sort = TRUE)

```

#### CONSISTENCY CHECK S4

Here we see whether the model is also significant in Study 3 (pretest
only)

TL;DR:

NO. 

Here we test whether the specification of the best fitting model to
predict trust is also a good fit to the data from Study 3 (pre-tests)
[note, this study was only run on block #1]

```{r, m7_study4}


## SETUP DATAFRAME
df <- df_graphs_all %>% 
  # filter only Study 1 and 3
  filter(Study == "Study3")
print("Data in Model")
table(df$Study, df$Assigned.Block)


################## FIT MODEL
f.s3 <-  "TRUST ~ BEAUTY X INTENT + INTENT X ALIGN + DATA + (1|PID)"
mm.s3 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + INTENT_z*ALIGN_z + DATA_z + (1|PID), data = df)
summary(mm.s3)
car::Anova(mm.s3, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxIxAD, mm.BxIDA, mm.BxID, rank = TRUE)
# anova(mm.BxIxAD, mm.BxIDA)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
plot_model(mm.s3, type = "est", show.intercept = TRUE, show.p=TRUE, show.values = TRUE) + labs(title = "Model Coefficients") + theme_minimal()


## see each two-way interaction
# print("two-way interaction")
# plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "INTENT_z")) + theme_minimal() + labs(subtitle ="", caption="")
# plot_model(mm.BxIxAD, type = "pred", terms = c("ALIGN_z", "INTENT_z")) + theme_minimal() + labs(subtitle ="",
# plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "ALIGN_z")) + theme_minimal() + labs(subtitle ="", caption = "")
# plot_model(mm.BxIxAD, type = "pred", terms = c("BEAUTY_z", "DATA_z")) + theme_minimal() + labs(subtitle ="", caption = "")


```

No, the model does not constintute a good fit for the Study 3 (pretest) data (only block 1). In this model, INTENT and DATA are no longer significant main effects, and neither interaction is significant either.  



## [3] MODELLING CHANGE

What predicts change in attitude?

### RECORD CHANGE
```{r}

# SETUP DATA FRAMES AND RECORD CHANGES FROM PRE-POST

## CATEGORICALS
df_cat <- df_questions_s3 %>% 
  filter( QUESTION %nin% ref_min_sd_questions) %>% 
  filter( QUESTION %nin% ref_min_conf_questions) %>% 
  filter( QUESTION %nin% ref_min_free_questions) %>% 
  filter( QUESTION != "LATENCY") %>%  
  droplevels() %>% 
  mutate(
    #set logical, did the value change?
    CHANGE_RAW = PRE!=POST,
    CHANGE_ABS = abs(CHANGE_RAW)
  )

  
## CONF QUESTIONS
df_conf <- df_questions_s3 %>% 
  filter( QUESTION %in% ref_min_conf_questions) %>% 
  droplevels() %>% 
  mutate(
    POST = as.numeric(POST),
    PRE = as.numeric(PRE),
    ## calculate change
    CHANGE_RAW = POST - PRE,
    ## calculate absolute values
    # PRE_abs = abs(PRE - 50),
    # POST_abs = abs(POST - 50),
    CHANGE_ABS = abs(CHANGE_RAW)
  )

## SD QUESTIONS
df_sd <- df_questions_s3 %>% 
  filter( QUESTION %in% ref_min_sd_questions) %>% 
  droplevels() %>% 
  mutate(
     POST = as.numeric(POST),
      PRE = as.numeric(PRE),
      ## calculate change
      CHANGE_RAW = POST - PRE,
      ## calculate absolute values
      # PRE_abs = abs(PRE - 50),
      # POST_abs = abs(POST - 50),
      CHANGE_ABS = abs(CHANGE_RAW)
  )


df_all <- rbind(df_cat,df_conf, df_sd) %>% 
  pivot_wider(
    names_from = QUESTION,
    names_glue = "{QUESTION}_{.value}",
    values_from = c(PRE,POST,CHANGE_RAW,CHANGE_ABS)
  ) %>% mutate(
    ID_CHANGE = as.logical(ID_CHANGE_RAW),
    ID_CHANGE = as.factor(ID_CHANGE),
    ENCOUNTER_CHANGE = as.logical(ENCOUNTER_CHANGE_RAW),
    ENCOUNTER_CHANGE = as.factor(ENCOUNTER_CHANGE)
  )



```

### MODEL CHANGE IN TRUST BY CATEGORICALS — CONTINUE THIS 
```{r}

df <- df_all 

## model 
m.1 <- lmer(TRUST_CHANGE_RAW ~ ALIGN_CHANGE_RAW + INTENT_CHANGE_RAW + (1|PID), data = df)
summary(m.1)
anova(m.1)
performance(m.1)
plot_model(m.1, type = "pred", terms=c("ALIGN_CHANGE_RAW","INTENT_CHANGE_ABS")) + labs(title = f.1)
plot_model(m.1, type = "pred", terms=c("STIMULUS","QUESTION")) + labs(title = f.1)

```

### MODEL ENCOUNTER
```{r}

df <- df_all

## glmer 
m.1 <- glmer( data = df, ENCOUNTER_CHANGE ~ STIMULUS + (1|PID),
              family = "binomial")
summary(m.1)
performance(m.1)


## glmer 
m.2 <- glmer( data = df, ENCOUNTER_CHANGE ~ STIMULUS + ID_CHANGE + (1|PID),
              family = "binomial")
summary(m.2)
compare_performance(m.1, m.2, rank =TRUE)


####### EXPLORATORY VISUALIZATIONS 




```




# !! USEFUL !! MODEL CHANGE IN ATTITUDE (SDS ONLY)

```{r}

df <- df_sd %>% 
  mutate(
    QUESTION = factor(QUESTION, levels=c("BEAUTY","DESIGN","DATA","POLITICS","ALIGN","TRUST","INTENT"))
  )

## linear model
f.1 <- "CHANGE ~ QUESTION + STIMULUS"
m.1 <- lmer(data = df, CHANGE_ABS ~ QUESTION + STIMULUS + (1|PID))
summary(m.1)  
anova(m.1)
performance(m.1)
plot_model(m.1, type = "pred", terms=c("QUESTION","STIMULUS")) + labs(title = f.1)
plot_model(m.1, type = "pred", terms=c("STIMULUS","QUESTION")) + labs(title = f.1)

## ixn model
f.2 <- "CHANGE ~ QUESTION * STIMULUS"
m.2 <- lmer(data = df, CHANGE_ABS ~ QUESTION * STIMULUS + (1|PID))
summary(m.2)  
anova(m.2)
performance(m.2)
plot_model(m.2, type = "pred", terms=c("QUESTION","STIMULUS")) + labs(title = f.2)
plot_model(m.2, type = "pred", terms=c("STIMULUS","QUESTION")) + labs(title = f.2)
  
## compare models
compare_performance(m.1, m.2, rank = TRUE)
anova(m.1, m.2)

```






### MODEL CHANGE IN ATTITUDE (incl categoricals and conf)
```{r}

ref_sd_change = data.frame(ref_min_sd_questions)
ref_sd_change <- ref_sd_change %>% 
  mutate(
    QUESTION = ref_min_sd_questions,
    RAW = paste0(QUESTION,"_CHANGE_RAW"),
    ABS = paste0(QUESTION,"_CHANGE_ABS")
  ) %>% select(-ref_min_sd_questions)



```





### DESCRIBE change in attitudes

#### By Question?

#### By Stimuli?

### CHANGE in trust?

### CHANGE in encounter?


# GENERATE GRAPHS
### [1] SAVE Qs Semantic Differential (aggregated)
```{r plot_ridglines_sds_questions_stimulus_studies_block1_pre_post}
  
#### DENSITY RIDGES#############################################################################
#### loop over questions and stimuli, vertically stack studies, color by sample

## DEFINE DF
df <- df_sd_questions_long_all%>% 
  #drop pilot data
  filter(Study != "Study0") %>% 
  #for Study 3 ONLY, set SAMPLE = TIME (for graphing purpose)
  mutate(
    Sample = case_when(Study =="Study3" ~ TIME ,
                       .default = Sample)) %>% 
  mutate(Sample = factor(Sample, levels = c("TUMBLR","GENERAL","POST","PRE"))) %>% 
  mutate(Study = factor(Study, levels=order_study)) %>% 
  droplevels()
  
print("Data in this chart")
table(df$STIMULUS,df$Study)
  

## DEFINE REFS
n_q <- length(levels(df$QUESTION))
questions <- ref_min_sd_questions #has qs in right order
labels <- ref_labels_min

## SET INITIAL VALUES
q <- questions[1]
x = list() #list of plots

## LOOP OVER STIMULI, LOOP OVER QUESTIONS


  i=0
  # print(s)
  for (q in questions) {
    i = i+1
    # print(i)
    # print(q)
  
    ## FILTER Q AND CALCULATE MEDIAN
    d <- df %>% filter(QUESTION ==q) %>% 
    group_by(Study,Sample) %>% 
    mutate(m=median(value)) ## calc median for printing on graph
  
    x[[i]] <- 
      ggplot(d, aes(x = value, y = Study, fill = Sample, color = Sample, )) +
      geom_density_ridges2(scale = 0.65, panel_scaling = TRUE, rel_min_height = 0.01, alpha = 0.25,
          # ## POINT JITTER GEOMETRY
          # jittered_points = TRUE, alpha = 0.7, scale = 0.9)+
           # ## RUG GEOMETRY
            jittered_points = TRUE,
            position = position_points_jitter(width = 0.5, height = 0),
            point_shape = '|', point_size = 3, point_alpha = 0.5) +
      scale_x_continuous(limits=c(0,100)) +
      scale_fill_manual(values = my_palettes(name="simple_samples", direction = "1")) +
      scale_color_manual(values = my_palettes(name="simple_samples", direction = "1")) +
      ## MEDIAN
      stat_summary(fun=median, geom="text", fontface = "bold", size= 5,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
      stat_summary(fun=median, geom="point", size=2) +
   
      labs (title = q, y = "", x = "") +
      guides(
        y = guide_axis_manual(labels = labels[q,"left"]),
        y.sec = guide_axis_manual(labels = labels[q,"right"]),
        # x.sec = guide_axis_manual(position = "top", title = q, breaks = NULL)
        ) +
      theme_ridges(grid = TRUE, center_axis_labels = TRUE) + easy_remove_legend() 
  
  
    
    ## JOIN QUESTION LEVEL PLOTS FOR THIS STIMULUS
    title <- paste0("ALL STIMULI_",q)
    p <- x[[i]] + plot_annotation(
     title = title,
     subtitle ="", caption = "(point is median)")  
    
    ## SAVE GRAPH FOR THIS STIMULIS 
  if(GRAPH_SAVE == TRUE) {
     ggsave(plot = p, path="figs/MVP/FIG_Descriptives/by_question", filename =paste0("FULL_STUDY_AGGREGATED_",q,".png"), units = c("in"), width = 8, height = 8,  bg='#ffffff'  )}
      
    
  }## END loop over questions
```










## TODO EVALUATE MOVE TO STASH

### (1) FULL VARIABLES STUDY 1, Study 0, Study2 (not stimulus balanced)

```{r}

#### Setup Data
df <- df_graphs %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 
  select(PID, Study, Assigned.Block, STIMULUS,STIMULUS_CATEGORY, MAKER_ID, MAKER_TRUST, CHART_TRUST, CHART_BEAUTY, CHART_INTENT, MAKER_DATA) %>% 
  mutate(
    TRUST_z = datawizard::standardise(CHART_TRUST),
    BEAUTY_z = datawizard::standardise(CHART_BEAUTY),
    INTENT_z = datawizard::standardise(CHART_INTENT),
    DATA_z = datawizard::standardise(MAKER_DATA)
  ) %>% 
  droplevels()

table(df$Study, df$Assigned.Block)

################## FIT MODEL
f.BxID <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.BxID <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.BxID)
car::Anova(mm.BxID, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.BxI, rank = TRUE)
# anova(mm.BxID, mm.BxI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxID, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.BxID, type = "pred", terms = c("BEAUTY_Z", "DATA_Z","INTENT_Z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

### (2) MINIMUM VARIABLES STUDY 1, Study 0, Study2, Study 3A (not stimulus balanced)

```{r}

#### Setup Data
df <- df_graphs_all
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.2 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.2 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.2)
car::Anova(mm.2, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.2, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.2, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.2, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

### (3) MINIMUM VARIABLES STUDY 1, Study2, Study 3A (not stimulus balanced) — NO Study 0

```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study != "Study2")
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.3 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.3 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.3)
car::Anova(mm.3, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.3, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.3, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.3, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

### (3) MINIMUM VARIABLES STUDY 1, Study2 (stimulus balanced) — NO Study 2, 4

```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study %nin% c("Study4","Study2"))
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.4 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.4 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.4)
car::Anova(mm.4, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.3, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.3, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.3, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

### !!!! (5) STUDY 1, 3, 3WAY (works for S1,S3 and S1,S3,S4)

```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study %nin% c("Study2"))
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
# f.4 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z*ALIGN_z + DATA_z + (1|PID), data = df)
summary(mm)
car::Anova(mm, type=3) #type 3 tests for interaction model



plot_model(mm, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
### THIS IS THE GOOD ONE
plot_model(mm, type = "pred", terms = c("BEAUTY_z", "INTENT_z","ALIGN_z")) + theme_minimal()
plot_model(mm, type = "pred", terms = c("BEAUTY_z", "INTENT_z","ALIGN_z","DATA_z")) + theme_minimal()

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = "", caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

# OLD

# AGGREGATED DATA

## (5.1.2) Survey Response Time

```{r demo-response-time}

df <- df_participants

# #TUMBLR
df.t <- df %>% filter(Distribution == "TUMBLR")
t.desc.duration <- psych::describe(df.t %>% pull(duration.min))

# #PROLIFIC
df.p <- df %>% filter(Distribution == "PROLIFIC")
p.desc.duration <- psych::describe(df.p %>% pull(duration.min))

## COMBINED for descriptives paragraph
a.desc.duration <- psych::describe(df %>% pull(duration.min))


```

**As Reported in Section 5.1.2 Procedure :**

STUDY 1, TUMBLR Across the TUMBLR sample (S1), responses from (n =
`r t.desc.duration$n` ) participants ranged from
`r round(t.desc.duration$min,0)` to `r round(t.desc.duration$max,0)`
minutes, with a mean response time of `r round(t.desc.duration$mean,0)`
minutes, SD = `r (round(t.desc.duration$sd,0))`.

STUDY 2, PROLIFIC Across the PROLIFIC sample (S2), responses from (n =
`r p.desc.duration$n` ) participants ranged from
`r round(p.desc.duration$min,0)` to `r round(p.desc.duration$max,0)`
minutes, with a mean response time of `r round(p.desc.duration$mean,0)`
minutes, SD = `r (round(p.desc.duration$sd,0))`.

Across the combined sample, responses from (n = `r a.desc.duration$n` )
participants ranged from `r round(a.desc.duration$min,0)` to
`r round(a.desc.duration$max,0)` minutes, with a mean response time of
`r round(a.desc.duration$mean,0)` minutes, SD =
`r (round(a.desc.duration$sd,0))`.

```{r demo-cleanup}
rm(df, a.desc.duration, t.desc.duration, p.desc.duration )
```

## (5.1.4) Participants

```{r demo-sample-size}

df <- df_participants

## FOR DESCRIPTIVES PARAGRAPH

# #TUMBLR
df.t <- df %>% filter(Distribution == "TUMBLR")
desc.gender.t <- table(df.t$D_gender) %>% prop.table()
names(desc.gender.t) <- levels(df.t$D_gender)
t_participants <- nrow(df.t)


# #PROLIFIC
df.p <- df %>% filter(Distribution == "PROLIFIC")
desc.gender.p <- table(df.p$D_gender) %>% prop.table()
names(desc.gender.p) <- levels(df.p$D_gender)
p_participants <- nrow(df.p)



```

**As Reported in Section 5.1.4 Participants :**

Combined, a total of `r p_participants + t_participants` participants
were recruited from US-located English speaking users of TUMBLR (n =
`r t_participants`) and PROLIFIC (n = `r p_participants`).

`r p_participants` individuals from PROLIFIC participated in Study 2, (
`r round(desc.gender.p["Female"],2)*100`% Female,#
`r round(desc.gender.p["Male"],2)*100`% Male,
`r round(desc.gender.p["Non-binary / third gender"],2)*100`% Non-binary,
`r round(desc.gender.p["Prefer not to say"],2)*100` % Prefer Not to Say,
`r round(desc.gender.p["Prefer to self-describe"],2)*100`% Prefer to
Self Describe).

`r t_participants` individuals from Tumblr participated in Study 2, (
`r round(desc.gender.t["Female"],2)*100`% Female,
`r round(desc.gender.t["Male"],2)*100`% Male,
`r round(desc.gender.t["Non-binary / third gender"],2)*100`% Non-binary,
`r round(desc.gender.t["Prefer to self-describe"],2)*100`% Prefer to
Self Describe, `r round(desc.gender.t["Prefer not to say"],2)*100`%
Prefer Not to Say. Other).

```{r demo-sample-cleanup}
rm(df, df.p, desc.gender.p, p_participants, df.t, desc.gender.t, t_participants)
```

## (5.1.4) Participants per Block

**As Reported in Section 5.1.4 Participants, there were \~ 53
participants per stimulus block**

```{r participant-block}

df <- df_participants
addmargins(table(df$Assigned.Block, df$Distribution))

```

## (FIG 5) Survey Question Distributions

**As Reported in Figure 5, descriptive statistics for in-scope survey
questions.**

```{r sparktable}

# # library(tinytable)
# # library(webshot2)

#### CUSTOM HORIZONTAL STACKED BARPLOT
g <- function(d, ...){

  p <- d$pal %>% unique
  ggplot(d, aes(x="", fill=value)) +
    geom_bar(stat="count", position = "stack") +
    scale_fill_manual(values=my_colors[[p]]) +
    coord_flip() + theme_void() + easy_remove_axes() + easy_remove_legend()
}


## SETUP LIST OF NUMERIC DATAFRAMES
all_q <- c("MAKER_CONF", "AGE_CONF", "GENDER_CONF", ref_sd_questions)

# ## SETUP NUMERIC DATAFRAME
df_num <- df_graphs %>% select(all_of(all_q))

## CALC MEANS
### MEANS
m <- sapply(df_num, FUN=mean)
m <- round(m,1)
m <- paste0("M=",m)
sd <- sapply(df_num, FUN=sd)
sd <- round(sd,1)
sd <- paste0("SD=",sd)
stat <- paste0(m," ",sd)


### CREATE LIST OF CATEGORICAL DATAFRAMES
id = df_graphs %>% select(MAKER_ID) %>%
  pivot_longer(cols=1)%>% mutate(pal="reds") %>% as.data.frame()
age = df_graphs %>% select(MAKER_AGE) %>%
  pivot_longer(cols=1)%>% mutate(pal="lightblues") %>% as.data.frame()
gender = df_graphs %>% select(MAKER_GENDER) %>%
  pivot_longer(cols=1)%>% mutate(pal="smallgreens") %>% as.data.frame()

df_cat <- list()
df_cat[["MAKER_ID"]] <- id
df_cat[["MAKER_AGE"]] <- age
df_cat[["MAKER_GENDER"]] <- gender

## CALC CAT PROPORTIONS
n <- nrow(id)
m_id <- table(id) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100) %>% map_df(rev) #reverse reading order
stat_id <- paste0(m_id$value, "(", m_id$prop,"%)") %>%  unlist() %>% paste0(collapse=''," ")

n <- nrow(age)
m_age <- table(age) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100)%>% map_df(rev)
stat_age <- paste0(m_age$value, "(", m_age$prop,"%)") %>%  unlist() %>% paste0(collapse=''," ")

n <- nrow(gender)
m_gender <- table(gender) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100)%>% map_df(rev)
stat_gender <- paste0(m_gender$value, "(", m_gender$prop,"%)")%>%  unlist() %>% paste0(collapse=''," ")

## SETUP QUESTIONS
questions <- c(ref_cat_questions, "MAKER_CONF", "AGE_CONF", "GENDER_CONF", ref_sd_questions) 


#### SETUP TABLE
tab <- data.frame(
  VARIABLE = questions,
  DISTRIBUTION = "",
  STATISTICS = c(stat_id, stat_age, stat_gender, stat)
)

### RENDER TABLE
t <- tinytable::tt(tab, theme = "void") %>%
  plot_tt(j=2, i= 1:3, fun=g, data = df_cat, height = 1.5) %>%
  plot_tt(j=2, i= 4:17, fun="density", data = df_num, color="darkgrey") %>%
  style_tt(j=2, align="c")

t
if(GRAPH_SAVE){
  save_tt(t, output="figs/fig_5_descriptives.png", overwrite = TRUE)
}
```

# BLOCK 2 DATA

## (5.4) Design Features Index Social Attributions

**As Reported in Section 5.4, here we visualize the semantic
differential scale survey questions for each stimulus in randomization
block #2**

### BLOCK 2 GRAPHS

```{r plot_halfeye_sds_BLOCK2, warning=FALSE}


#DEFINE BLOCK 2 STIMULI
stimuli <- c("B2-1" ,"B2-2", "B2-3", "B2-4")
graphs <- list()

## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)
  
  graphs[[i]] <- g

  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/", filename =paste0("fig_7_BLOCK_2",s,"_ggdist.png"), units = c("in"), width = 10, height = 14,bg='#ffffff'   )
  }


} ## END LOOP 

graphs
```

### BLOCK 1 GRAPHS

```{r plot_halfeye_sds_BLOCK1, warning=FALSE}


#DEFINE BLOCK 1 STIMULI
stimuli <- c("B1-1" ,"B1-2", "B1-3", "B1-4")
graphs <- list()

## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)
  
  graphs[[i]] <- g

  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/", filename =paste0("BLOCK_1_",s,"_ggdist.png"), units = c("in"), width = 10, height = 14,bg='#ffffff'   )
  }


} ## END LOOP 

graphs
```

# ADDITIONAL BLOCKS

**In addition to the descriptive analysis of stimuli in Block 2 that is
reported in the manuscript, here we create visualize the semantic
differential scale for *each* stimulus in Study 2.**

## SD questions for each stimulus

```{r plot_halfeye_sdsplot_ALL, warning=FALSE}


#DEFINE STIMULI
df <- df_graphs
stimuli <- levels(df$STIMULUS)
graphs <- list()


## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)

  graphs[[i]] <- g
  
  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/other_blocks/", filename =paste0(s,"_ggdist.png"), units = c("in"), width = 10, height = 14,  bg='#ffffff'  )}
  

  
  
} ## END LOOP 

graphs
```

# SESSION

```{r session}
sessionInfo()
```
