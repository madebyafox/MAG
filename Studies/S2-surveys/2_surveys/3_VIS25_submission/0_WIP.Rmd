---
title: "WIP ANALYSIS"
author: "ANONYMIZED"
date: "2024-02-24"
output:
  html_document:
    theme: cosmo
    code_folding: hide
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 6
  pdf_document:
    toc: yes
    toc_depth: '5'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
editor_options: 
  markdown: 
    wrap: 72
---

# SETUP

### Import Packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(psych) #describe() & efa
library(tidyverse) #all the things
library(magrittr) #special pipes like %<>%
library(summarytools) #data quality
library(lubridate) #dealing with dates
library(tinytable) ##sparkline tables 
library(webshot2) ##saving sparkline tables

#EDA
library(qacBase)

#VIZ
library(ggformula) #regression syntax viz
library(ggstatsplot) #dummies
library(gghalves) #half boxplots 
library(GGally) #extends ggplot for EDA 
library(corrplot) #sophisticated correlation plots
library(ggeasy) #easy labelling
library(ggh4x) #guides [dual axes]
library(patchwork) #multi-plot layout
library(ggdist) #raincloud plots and other distributionals
library(viridis) #color palettes
library(RColorBrewer) #color palettes
library(plotly) # interactive graphs
library(paletteer) #more palettes
library(interactions) ##easier regression ixn plots.srlsy
library(tidygraph)

#MODELLING
library(jtools) #Social Science regression utilities
library(easystats) #modelling helpers
library(see)
library(sjPlot)
library(lme4)
library(lmerTest) #for CIs in glmer
# library(mixed) ## utilities for glmers 
library(jmv) ## jamovi EFA


#STATISTICAL TESTS 
library(kSamples) #AD K-SAMPLE TEST (for distribution comparison)
library(rstatix) #FRIEDMAN'S TESTS and effect sizes 

#CONFIG
options(readr.show_col_types = FALSE) #don't show coltypes on read_csv
n_blocks = 6

## IMPORTANT 
GRAPH_SAVE = TRUE #set to true to generate all the SD graphs and save to folders 
source("graphing_functions.R") #import graphing palettes and custom functions

```

### Import References

```{r import-refs, message=FALSE, warning = FALSE}

############## IMPORT REFERENCE FILES
ref_stimuli <- readRDS("data/input/REFERENCE/ref_stimuli.rds")
ref_labels <- readRDS("data/input/REFERENCE/ref_labels.rds")


############## SETUP Graph Labels
ref_stim_id <- levels(ref_stimuli$ID)
ref_cat_questions <- c("MAKER_ID","MAKER_AGE","MAKER_GENDER")
ref_free_response <- c("MAKER_DETAIL", "MAKER_EXPLAIN", "TOOL_DETAIL", "CHART_EXPLAIN")
ref_conf_questions <- c("MAKER_CONF", "AGE_CONF", "GENDER_CONF", "TOOL_CONF")
ref_sd_questions <- rownames(ref_labels)
ref_blocks <- c(1,2,3,4,5,6)


############## FULL QUESTION SET FOR S1_3
ref_sd_questions <- c("MAKER_DESIGN","MAKER_DATA",
                      "MAKER_POLITIC", "MAKER_ARGUE","MAKER_SELF","MAKER_ALIGN","MAKER_TRUST",
                      "CHART_TRUST", "CHART_INTENT", "CHART_LIKE", "CHART_BEAUTY")

ref_sd_questions_z <- c("MAKER_DESIGN_z","MAKER_DATA_z",
                      "MAKER_POLITIC_z", "MAKER_ARGUE_z","MAKER_SELF_z","MAKER_ALIGN_z","MAKER_TRUST_z",
                      "CHART_TRUST_z", "CHART_INTENT_z", "CHART_LIKE_z", "CHART_BEAUTY_z")


############## MINIMAL QUESTION SET FOR STUDY 4
ref_min_sd_questions <-  c("DESIGN","DATA","POLITICS", "TRUST","ALIGN","BEAUTY","INTENT")
ref_min_sd_questions_z <-  c("DESIGN_z","DATA_z","POLITICS_z", "TRUST_z","ALIGN_z","BEAUTY_z","INTENT_z")



```

### Import Data

```{r import-data, message=FALSE, warning = FALSE}

############## IMPORT Study 1_3 DATA FILES
df_participants <- readRDS("data/output/Study_1_2_3/df_participants.rds") #1 row per participant — demographic
df_graphs <- readRDS("data/output/Study_1_2_3/df_graphs.rds") #only categorical and numeric questions
df_graphs_z <- readRDS("data/output/Study_1_2_3/df_graphs_z.rds") #only categorical and numeric questions
df_sd_questions_long <- readRDS("data/output/Study_1_2_3/df_sd_questions_long.rds") # only sd questions LONG


############## IMPORT Study 4 DATA FILES



############## IMPORT COMBINED DATA FILES
df_graphs_all <- readRDS("data/output/COMBINED/df_graphs_ALL.rds") 
```

# NEW

## EXPLORATORY FACTOR ANALYSIS

```{r}
print("DATA AVAILABLE WITH FULL QUESTION SET")
table(df_graphs$Study, df_graphs$Assigned.Block)

print("DATA AVAILABLE WITH REDUCED QUESTION SET")
table(df_graphs_all$Study, df_graphs_all$Assigned.Block)
```

Key questions to address in the EFA analysis:

1.  Include full set of variables (Study 1,2,3) OR only only minimal
    variables included in S4 as well
2.  Include data from Study 2 and Study 4 (only block 1) ?
3.  Do analysis just for block 1?
4.  Do analysis just for super-powered image?
5.  Do analysis just for data over all blocks (Study 1 + Study 3)




PRE-REQUISISITES
-   Bartlett’s Test of Sphericity Tests if the correlation matrix is
    significantly different from an identity matrix (no correlations). p
    \< 0.05 indicates sufficient correlations.
-   Kaiser-Meyer-Olkin (KMO) Measure Assesses sampling adequacy for EFA
    (overall and per variable). Overall KMO ≥ 0.60 is acceptable. KMO ≥
    0.80 is meritorious. Variables with KMO \< 0.50 might need removal.

OUTCOMES
-   FACTOR LOADINGS:
Factor loadings represent the correlation between each variable and a factor. Higher absolute loadings indicate stronger relationships between the item and the factor. ≥ 0.70	Very strong loading (ideal, but rare in practice). 0.50 – 0.70	Moderate to strong—good indicator of factor membership. 0.30 – 0.50	Weak to moderate—may be acceptable depending on context and theory. < 0.30	Weak—often considered too low to retain, unless justified theoretically.

    
-   (h^2) H2: COMMUNALITY: indicates the proportion of variance in a variable that is explained by the extracted factors. It ranges from 0 to 1 (or 0% to 100% if expressed as a percentage). Think of it as shared variance: how much of a variable's variance is accounted for by the common factors.
-   Communality Value	Interpretation: ≥ 0.60	Excellent—variable is well explained by the factors. 0.40 – 0.60	Acceptable in many cases, especially in social sciences. < 0.40	Low—variable may not fit well in the factor model. Consider revising or dropping it (but consider theory first).

- (u²): U2: UNIQUENESS: Proportion of variance unique to the variable, not explained by factors.
- com: com: COMPLEXITY: Complexity (com) measures how many factors a variable meaningfully loads onto.com Value	Meaning
1.0	The variable loads strongly on one factor (simple structure). > 1.0	The variable loads on multiple factors, with complexity increasing as it spreads across more factors.
Higher values (e.g., 1.5–2.5)	The variable is cross-loading across factors, making interpretation harder.


SUMMARY
    
- Factor Loadings: Ideally ≥ 0.50 on one factor and low on the others.    
- Communalities (H2): Ideally ≥ 0.40 for most items.
- Cross-loadings: Avoid or minimize; interpret with caution.
- Theoretical Coherence: Even if a loading is statistically "low," theory may justify its retention.    
    
### (1) EFA : REDUCED VARS

#### !!! (1.1) EFA : REDUCED VARS : S1, S2, S3, S4(PRE) (UNBALANCED BLOCKS)

```{r}

## SETUP DATA
df <- df_graphs_all%>% select(all_of(ref_min_sd_questions_z))
x <- ref_min_sd_questions_z

## RUN EFA JAMOVI STYLE
jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)


## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

```


#### (1.2) EFA : REDUCED VARS : S1, S3 (BALANCED BLOCKS)

```{r}

## SETUP DATA
df <- df_graphs_all%>% filter(Study %in% c("Study1","Study3"))
# table(df$Study, df$Assigned.Block)
x <- ref_min_sd_questions_z

## RUN EFA JAMOVI STYLE
jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)


## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

```




### (2) EFA : FULL VARS

#### (2.1) EFA : FULL VARS : S1,S3 (BALANCED BLOCKS)
```{r}

## SETUP DATA
df <- df_graphs_z%>% filter(Study %in% c("Study1","Study3"))
table(df$Study, df$Assigned.Block)
x <- ref_sd_questions_z

## RUN EFA JAMOVI STYLE
jmv::efa(
    data = df,
    vars = as.vector(x),
    # nFactors = 3,
    extraction = "ml",
    sortLoadings = FALSE,
    screePlot = TRUE,
    eigen = FALSE,
    factorCor = TRUE,
    factorSummary = TRUE,
    modelFit = TRUE,
    kmo = TRUE,
    bartlett = TRUE)


## RUN EFA PSYCH PACKAGE
# df <- df_graphs_all %>% select(all_of(ref_min_sd_questions_z))
# 
# # EFA using Maximum Likelihood extraction and Oblimin rotation
# efa_result <- fa(df, 
#                  nfactors = 3, 
#                  rotate = "oblimin", 
#                  fm = "ml")
# 
# # View the entire EFA output
# print(efa_result, cut = 0.3)
# # View entire result w/o cutoff
# # efa_result
# # Optional: visualize factor diagram
# fa.diagram(efa_result)

```










## QUICK TRUST MODEL

### (1) FULL VARIABLES STUDY 1, STUDY 2, STUDY3 (not stimulus balanced)
```{r}

#### Setup Data
df <- df_graphs %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 
  select(PID, Study, Assigned.Block, STIMULUS,STIMULUS_CATEGORY, MAKER_ID, MAKER_TRUST, CHART_TRUST, CHART_BEAUTY, CHART_INTENT, MAKER_DATA) %>% 
  mutate(
    TRUST_z = datawizard::standardise(CHART_TRUST),
    BEAUTY_z = datawizard::standardise(CHART_BEAUTY),
    INTENT_z = datawizard::standardise(CHART_INTENT),
    DATA_z = datawizard::standardise(MAKER_DATA)
  ) %>% 
  droplevels()

table(df$Study, df$Assigned.Block)

################## FIT MODEL
f.BxID <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.BxID <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.BxID)
car::Anova(mm.BxID, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.BxI, rank = TRUE)
# anova(mm.BxID, mm.BxI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxID, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.BxID, type = "pred", terms = c("BEAUTY_Z", "DATA_Z","INTENT_Z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```





### (2) MINIMUM VARIABLES STUDY 1, STUDY 2, STUDY3, STUDY 4A (not stimulus balanced)
```{r}

#### Setup Data
df <- df_graphs_all
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.2 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.2 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.2)
car::Anova(mm.2, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.2, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.2, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.2, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```


### (3) MINIMUM VARIABLES STUDY 1, STUDY3, STUDY 4A (not stimulus balanced) — NO STUDY 2
```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study != "Study2")
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.3 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.3 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.3)
car::Anova(mm.3, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.3, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.3, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.3, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```











### (3) MINIMUM VARIABLES STUDY 1, STUDY3  (stimulus balanced) — NO STUDY 2, 4
```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study %nin% c("Study4","Study2"))
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
f.4 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.4 <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z + DATA_z + (1|PID), data = df)
summary(mm.4)
car::Anova(mm.4, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.3, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm.3, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.3, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```

### (TODO 3WAY INTERACTION)

### !!!! (5) STUDY 1, 3, 3WAY (works for S1,S3 and S1,S3,S4)
```{r}

#### Setup Data
df <- df_graphs_all %>% filter(Study %nin% c("Study2"))
table(df$Study, df$Assigned.Block)
# %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 

################## FIT MODEL
# f.4 <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm <- lmer(TRUST_z ~ BEAUTY_z * INTENT_z*ALIGN_z + DATA_z + (1|PID), data = df)
summary(mm)
car::Anova(mm, type=3) #type 3 tests for interaction model



plot_model(mm, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
### THIS IS THE GOOD ONE
plot_model(mm, type = "pred", terms = c("BEAUTY_z", "INTENT_z","ALIGN_z")) + theme_minimal()
plot_model(mm, type = "pred", terms = c("BEAUTY_z", "INTENT_z","ALIGN_z","DATA_z")) + theme_minimal()

################## COMPARE MODEL
# compare_performance(mm.BxID, mm.2, rank = TRUE)
# anova(mm.BxID, mm.2)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <-  plot_model(mm, type = "pred", terms = c("BEAUTY_z", "DATA_z","INTENT_z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = "", caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

```









# OLD

# AGGREGATED DATA

## (5.1.2) Survey Response Time

```{r demo-response-time}

df <- df_participants

# #TUMBLR
df.t <- df %>% filter(Distribution == "TUMBLR")
t.desc.duration <- psych::describe(df.t %>% pull(duration.min))

# #PROLIFIC
df.p <- df %>% filter(Distribution == "PROLIFIC")
p.desc.duration <- psych::describe(df.p %>% pull(duration.min))

## COMBINED for descriptives paragraph
a.desc.duration <- psych::describe(df %>% pull(duration.min))


```

**As Reported in Section 5.1.2 Procedure :**

STUDY 1, TUMBLR Across the TUMBLR sample (S1), responses from (n =
`r t.desc.duration$n` ) participants ranged from
`r round(t.desc.duration$min,0)` to `r round(t.desc.duration$max,0)`
minutes, with a mean response time of `r round(t.desc.duration$mean,0)`
minutes, SD = `r (round(t.desc.duration$sd,0))`.

STUDY 2, PROLIFIC Across the PROLIFIC sample (S2), responses from (n =
`r p.desc.duration$n` ) participants ranged from
`r round(p.desc.duration$min,0)` to `r round(p.desc.duration$max,0)`
minutes, with a mean response time of `r round(p.desc.duration$mean,0)`
minutes, SD = `r (round(p.desc.duration$sd,0))`.

Across the combined sample, responses from (n = `r a.desc.duration$n` )
participants ranged from `r round(a.desc.duration$min,0)` to
`r round(a.desc.duration$max,0)` minutes, with a mean response time of
`r round(a.desc.duration$mean,0)` minutes, SD =
`r (round(a.desc.duration$sd,0))`.

```{r demo-cleanup}
rm(df, a.desc.duration, t.desc.duration, p.desc.duration )
```

## (5.1.4) Participants

```{r demo-sample-size}

df <- df_participants

## FOR DESCRIPTIVES PARAGRAPH

# #TUMBLR
df.t <- df %>% filter(Distribution == "TUMBLR")
desc.gender.t <- table(df.t$D_gender) %>% prop.table()
names(desc.gender.t) <- levels(df.t$D_gender)
t_participants <- nrow(df.t)


# #PROLIFIC
df.p <- df %>% filter(Distribution == "PROLIFIC")
desc.gender.p <- table(df.p$D_gender) %>% prop.table()
names(desc.gender.p) <- levels(df.p$D_gender)
p_participants <- nrow(df.p)



```

**As Reported in Section 5.1.4 Participants :**

Combined, a total of `r p_participants + t_participants` participants
were recruited from US-located English speaking users of TUMBLR (n =
`r t_participants`) and PROLIFIC (n = `r p_participants`).

`r p_participants` individuals from PROLIFIC participated in Study 2, (
`r round(desc.gender.p["Female"],2)*100`% Female,#
`r round(desc.gender.p["Male"],2)*100`% Male,
`r round(desc.gender.p["Non-binary / third gender"],2)*100`% Non-binary,
`r round(desc.gender.p["Prefer not to say"],2)*100` % Prefer Not to Say,
`r round(desc.gender.p["Prefer to self-describe"],2)*100`% Prefer to
Self Describe).

`r t_participants` individuals from Tumblr participated in Study 2, (
`r round(desc.gender.t["Female"],2)*100`% Female,
`r round(desc.gender.t["Male"],2)*100`% Male,
`r round(desc.gender.t["Non-binary / third gender"],2)*100`% Non-binary,
`r round(desc.gender.t["Prefer to self-describe"],2)*100`% Prefer to
Self Describe, `r round(desc.gender.t["Prefer not to say"],2)*100`%
Prefer Not to Say. Other).

```{r demo-sample-cleanup}
rm(df, df.p, desc.gender.p, p_participants, df.t, desc.gender.t, t_participants)
```

## (5.1.4) Participants per Block

**As Reported in Section 5.1.4 Participants, there were \~ 53
participants per stimulus block**

```{r participant-block}

df <- df_participants
addmargins(table(df$Assigned.Block, df$Distribution))

```

## (FIG 5) Survey Question Distributions

**As Reported in Figure 5, descriptive statistics for in-scope survey
questions.**

```{r sparktable}

# # library(tinytable)
# # library(webshot2)

#### CUSTOM HORIZONTAL STACKED BARPLOT
g <- function(d, ...){

  p <- d$pal %>% unique
  ggplot(d, aes(x="", fill=value)) +
    geom_bar(stat="count", position = "stack") +
    scale_fill_manual(values=my_colors[[p]]) +
    coord_flip() + theme_void() + easy_remove_axes() + easy_remove_legend()
}


## SETUP LIST OF NUMERIC DATAFRAMES
all_q <- c("MAKER_CONF", "AGE_CONF", "GENDER_CONF", ref_sd_questions)

# ## SETUP NUMERIC DATAFRAME
df_num <- df_graphs %>% select(all_of(all_q))

## CALC MEANS
### MEANS
m <- sapply(df_num, FUN=mean)
m <- round(m,1)
m <- paste0("M=",m)
sd <- sapply(df_num, FUN=sd)
sd <- round(sd,1)
sd <- paste0("SD=",sd)
stat <- paste0(m," ",sd)


### CREATE LIST OF CATEGORICAL DATAFRAMES
id = df_graphs %>% select(MAKER_ID) %>%
  pivot_longer(cols=1)%>% mutate(pal="reds") %>% as.data.frame()
age = df_graphs %>% select(MAKER_AGE) %>%
  pivot_longer(cols=1)%>% mutate(pal="lightblues") %>% as.data.frame()
gender = df_graphs %>% select(MAKER_GENDER) %>%
  pivot_longer(cols=1)%>% mutate(pal="smallgreens") %>% as.data.frame()

df_cat <- list()
df_cat[["MAKER_ID"]] <- id
df_cat[["MAKER_AGE"]] <- age
df_cat[["MAKER_GENDER"]] <- gender

## CALC CAT PROPORTIONS
n <- nrow(id)
m_id <- table(id) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100) %>% map_df(rev) #reverse reading order
stat_id <- paste0(m_id$value, "(", m_id$prop,"%)") %>%  unlist() %>% paste0(collapse=''," ")

n <- nrow(age)
m_age <- table(age) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100)%>% map_df(rev)
stat_age <- paste0(m_age$value, "(", m_age$prop,"%)") %>%  unlist() %>% paste0(collapse=''," ")

n <- nrow(gender)
m_gender <- table(gender) %>% as.data.frame() %>% mutate(prop = round(Freq/n, 2)*100)%>% map_df(rev)
stat_gender <- paste0(m_gender$value, "(", m_gender$prop,"%)")%>%  unlist() %>% paste0(collapse=''," ")

## SETUP QUESTIONS
questions <- c(ref_cat_questions, "MAKER_CONF", "AGE_CONF", "GENDER_CONF", ref_sd_questions) 


#### SETUP TABLE
tab <- data.frame(
  VARIABLE = questions,
  DISTRIBUTION = "",
  STATISTICS = c(stat_id, stat_age, stat_gender, stat)
)

### RENDER TABLE
t <- tinytable::tt(tab, theme = "void") %>%
  plot_tt(j=2, i= 1:3, fun=g, data = df_cat, height = 1.5) %>%
  plot_tt(j=2, i= 4:17, fun="density", data = df_num, color="darkgrey") %>%
  style_tt(j=2, align="c")

t
if(GRAPH_SAVE){
  save_tt(t, output="figs/fig_5_descriptives.png", overwrite = TRUE)
}
```

# BLOCK 2 DATA

## (5.4) Design Features Index Social Attributions

**As Reported in Section 5.4, here we visualize the semantic
differential scale survey questions for each stimulus in randomization
block #2**

### BLOCK 2 GRAPHS

```{r plot_halfeye_sds_BLOCK2, warning=FALSE}


#DEFINE BLOCK 2 STIMULI
stimuli <- c("B2-1" ,"B2-2", "B2-3", "B2-4")
graphs <- list()

## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)
  
  graphs[[i]] <- g

  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/", filename =paste0("fig_7_BLOCK_2",s,"_ggdist.png"), units = c("in"), width = 10, height = 14,bg='#ffffff'   )
  }


} ## END LOOP 

graphs
```

### BLOCK 1 GRAPHS

```{r plot_halfeye_sds_BLOCK1, warning=FALSE}


#DEFINE BLOCK 1 STIMULI
stimuli <- c("B1-1" ,"B1-2", "B1-3", "B1-4")
graphs <- list()

## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)
  
  graphs[[i]] <- g

  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/", filename =paste0("BLOCK_1_",s,"_ggdist.png"), units = c("in"), width = 10, height = 14,bg='#ffffff'   )
  }


} ## END LOOP 

graphs
```

# PREDICTING TRUST

## (5.5) Social Inferences & Trust: Makers Matter

**As reported in Section 5.5**

What predicts CHART-TRUST? Recent work in psychology (Lin & Thorton,
2021) suggests that beauty is a strong predictor of trust. However, from
our free response data, we have reason to believe the relationship is
not this simple. For example, some participants explained that very
aesthetically pleasing images were likely meant to be persuasive and
thus were less trustworthy. Similarly, we observed that participants
frequently talked about a maker's data competency in relation to their
trustworthiness. On this basis, we expect that in predicting
`CHART_TRUST`: (1) there will be a significant interaction between
`CHART_BEAUTY` and `CHART_INTENT`, and (2) that `MAKER_DATA`
(competency) will also be a significant predictor.

We test this hypothesis by fitting a series of linear mixed effects
models, with `PID` (participant unique identifier) as a random intercept
to account for repeated measures. All continuous measures were
originally taken on a (0-100) scale. In these models, all continuous
predictors are first z-scored. We compare model fit via ChiSquared
difference tests and likelihood ratio tests (for nested models).

#### Setup Data

```{r hypo-trust_beauty_intent-data}

df <- df_graphs %>%
  ## FILTER OUT B0-0 COMMON STIMULUS (so cells can be balanced)
  # filter(STIMULUS != "B0-0") %>% 
  select(PID, STIMULUS,STIMULUS_CATEGORY, MAKER_ID, MAKER_TRUST, CHART_TRUST, CHART_BEAUTY, CHART_INTENT, MAKER_DATA) %>% 
  mutate(
    TRUST_Z = datawizard::standardise(CHART_TRUST),
    BEAUTY_Z = datawizard::standardise(CHART_BEAUTY),
    INTENT_Z = datawizard::standardise(CHART_INTENT),
    DATA_Z = datawizard::standardise(MAKER_DATA)
  ) %>% 
  droplevels()
```

#### M1 \| TRUST \~ BEAUTY

We begin by fitting a linear mixed effects, model predicting
`CHART_TRUST` by `CHART_BEAUTY` to see whether our data support the
claims made by Lin & Thorton, 2021.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

```{r, m1}

################## FIT MODEL
f.B <-  "TRUST ~ BEAUTY + (1|PID)"
mm.B <- lmer(TRUST_Z ~ BEAUTY_Z + (1|PID), data = df)
summary(mm.B)
car::Anova(mm.B, type=2)
performance(mm.B)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.B, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.B, type = "pred", terms = "BEAUTY_Z") +  theme_minimal()
(g <- (e+p) + plot_annotation(title = f.B))

```

A model predicting `CHART-TRUST` by `CHART_BEAUTY` explains 30% variance
in `CHART_TRUST`, with 22% variance explained by a significant main
effect of `CHART_BEAUTY` ($t(1554) = 21.59, p <
.001$). The model coefficient indicates that for every 1 standard
deviation increase in `CHART-BEAUTY`, `CHART-TRUST` increases on average
by 0.47 SD.

**Model 1 supports the argument of Lin & Thorton (2021) that graphs
judged to be more attractive are also judged as more trustworthy.**

#### M2 \| TRUST \~ BEAUTY + INTENT

Here we add a main effect term `CHART_INTENT` as a predictor to the
previous model and compare fit with Model 1, to determine whether a
social attribution (in this case inference about the chart's intent) is
also predictive of `CHART_TRUST`.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

```{r m2}

################## FIT MODEL
f.BI <-  "TRUST ~ BEAUTY + INTENT + (1|PID)"
mm.BI <- lmer(TRUST_Z ~ BEAUTY_Z + INTENT_Z + (1|PID), data = df)
summary(mm.BI)
car::Anova(mm.BI, type=2)

################## COMPARE MODEL
compare_performance(mm.BI, mm.B, rank = TRUE)
anova(mm.BI, mm.B)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BI, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BI, type = "pred", terms = c("BEAUTY_Z", "INTENT_Z")) + theme_minimal()
(g <- (e+p) + plot_annotation(title = f.B, caption="low intent = inform, high intent = persuade"))

```

A model predicting `CHART-TRUST` by a linear combination of
`CHART_BEAUTY` and `CHART_INTENT` explains 49% variance in
`CHART_TRUST`, with 41% variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($t(1532) = 22.04, p <.001$), and

2.  A significant main effect of `CHART_INTENT`
    ($t(1581) = -22.83, p <.001$).

    The model coefficients indicates that for every 1 standard deviation
    increase in `CHART-BEAUTY`, `CHART-TRUST` increases on average by
    0.42 SD (more beauty corresponds to more trust). For every 1
    standard deviation increase in `CHART_INTENT`, (where LOW values
    correspond to intent to INFORM and high values correspond to intent
    to PERSUADE) `CHART-TRUST` decreases by 0.44 SD (more persuasive
    corresponds to less trust).

Further, model comparisons indicate that MODEL 2 (including
`CHART_INTENT`) is a significantly better fit to the data
($\chi^2(1) = 448 , p < 0.001$) than MODEL 1 including `CHART_BEAUTY`
alone.

**Model 2 supports our claim that social attributions (in this case, an
inference about the communicative intent of the chart) *also* predict
beauty, above and beyond the beauty-centric argument of Lin & Thorton
(2021) that graphs judged to be more attractive are also judged as more
trustworthy.**

#### M3 \| TRUST \~ BEAUTY X INTENT

Here we fit a model with `CHART_INTENT` as an **interaction** with
`CHART_BEAUTY`, and compare with the previous model (with the simple
linear combination of the two predictors) to determine whether simply
affecting `CHART_TRUST`, the social attribution of `CHART_INTENT`
**moderates** the effect of `CHART_BEAUTY` on `CHART_TRUST`.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

```{r m3}

################## FIT MODEL
f.BxI <-  "TRUST ~ BEAUTY X INTENT + (1|PID)"
mm.BxI <- lmer(TRUST_Z ~ BEAUTY_Z * INTENT_Z + (1|PID), data = df)
summary(mm.BxI)
car::Anova(mm.BxI, type=3)  #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxI, mm.BI, rank = TRUE)
anova(mm.BxI, mm.BI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxI, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BxI, type = "int", terms = c("INTENT_Z","BEAUTY_Z"),mdrt.values = "all") + theme_minimal()
(g <- (e+p) + plot_annotation(title = f.BxI, caption="low intent = inform, high intent = persuade", subtitle = f.BxI))

```

A model predicting `CHART-TRUST` by a linear **interaction** of
`CHART_BEAUTY` and `CHART_INTENT` explains 51% variance in
`CHART_TRUST`, with 42% variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 487, p <.001$)

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 486, p <.001$)

3.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 49, p <.001$)

    The model coefficients indicates that for every 1 standard deviation
    increase in `CHART-BEAUTY`, `CHART-TRUST` increases on average by
    0.41 SD (more beauty corresponds to more trust). For every 1
    standard deviation increase in `CHART_INTENT`, (where LOW values
    correspond to intent to INFORM and high values correspond to intent
    to PERSUADE) `CHART-TRUST` decreases on average by 0.42 SD (more
    persuasive corresponds to less trust). The significant interaction
    term indicates the difference in slope between the two main effects,
    that is to say, that the effect of `CHART_BEAUTY` on `CHART_TRUST`
    is **moderated** such that the effect of `CHART_BEAUTY` is
    *minimized* when `CHART_INTENT` is attributed as more informative
    (lower values of chart_intent) than persuasive (higher values of
    chart_intent)

Further, model comparisons indicate that MODEL 3 (an interaction rather
than MODEL 2 with a linear combination of `CHART_BEAUTY` and
`CHART_INTENT`) is a significantly better fit to the data
($\chi^2(1)=48.5 , p < 0.001$).

**Model 3 supports our claim that social attributions (in this case, an
inference about the communicative intent of the chart) *also* predict
beauty, and in fact can change (moderate) the effect of beauty on
trust.**

#### M4 \| TRUST \~ BEAUTY X INTENT + MAKER_DATA

Here we add `MAKER_DATA` competency to our previous model to determine
whether a viewer's inferences about the data analysis ability of the
chart's maker affect assesments of the chart's trustworthiness.

-   (`CHART_TRUST` 0 = not at all untrustworthy, 100 = very trustworthy)

-   (`CHART_BEAUTY` 0 = not at all aesthetically pleasing , 100 = very
    aesthetically pleasing)

-   (`CHART_INTENT` 0 = to *inform* , 100 = *persuade*)

-   (`MAKER_DATA` 0 = *professional* in data analysis , 100 =
    *layperson* in data analysis)

```{r, m4}

################## FIT MODEL
f.BxID <-  "TRUST ~ BEAUTY X INTENT + DATA (1|PID)"
mm.BxID <- lmer(TRUST_Z ~ BEAUTY_Z * INTENT_Z + DATA_Z + (1|PID), data = df)
summary(mm.BxID)
car::Anova(mm.BxID, type=3) #type 3 tests for interaction model

################## COMPARE MODEL
compare_performance(mm.BxID, mm.BxI, rank = TRUE)
anova(mm.BxID, mm.BxI)

################## PLOT MODEL
## PLOT MODEL COEFFICIENTS
e <- plot_model(mm.BxID, type = "est", show.intercept = TRUE) + labs(title = "Model Coefficients") + theme_minimal()
## PLOT MODEL PREDICTIONS
p <- plot_model(mm.BxID, type = "pred", terms = c("INTENT_Z", "BEAUTY_Z", "DATA_Z")) + theme_minimal()
(g <- (e/p) + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID))

if(GRAPH_SAVE){
 ggsave(g, scale =1, filename = "figs/fig_9_mm.BxID.png", width = 14, height = 6, dpi = 320, limitsize = FALSE,bg='#ffffff')
 tab_model(mm.BxID, file = "figs/fig_9_mm.BxID_table.html")
}


```

A model predicting `CHART-TRUST` by a linear **interaction** of
`CHART_BEAUTY` and `CHART_INTENT` as well as a main effect of
`MAKER_DATA` competency explains 54% variance in `CHART_TRUST`, with 45%
variance explained by fixed effects alone:

1.  A significant main effect of `CHART_BEAUTY`
    ($\chi^2(1) = 429, p <.001$)

2.  A significant main effect of `CHART_INTENT`
    ($\chi^2(1) = 354, p <.001$)

3.  A significant main effect of `MAKER_DATA`
    ($\chi^2(1) = 91, p <.001$)

4.  A significant interaction between `CHART_BEAUTY` and `CHART_INTENT`
    ($\chi^2(1) = 44, p <.001$)

    The model coefficients indicates that for every 1 standard deviation
    increase in `MAKER_DATA`, `CHART-TRUST` decreases on average by 0.19
    SD (less expertise/more layperson corresponds to lower trust). For
    every 1 standard deviation increase in `CHART-BEAUTY`, `CHART-TRUST`
    increases on average by 0.38 SD (more beauty corresponds to more
    trust). For every 1 standard deviation increase in `CHART_INTENT`,
    (where LOW values correspond to intent to INFORM and high values
    correspond to intent to PERSUADE) `CHART-TRUST` decreases on average
    by 0.37 SD ( persuasive corresponds to less trust; informative
    corresponds to more trust). The significant interaction term
    indicates the difference in slope between the main effects for
    `CHART_BEAUTY` and `CHART_INTENT`, that is to say, that the effect
    of `CHART_BEAUTY` on `CHART_TRUST` is **moderated** such that the
    effect of `CHART_BEAUTY` is *minimized* when `CHART_INTENT` is
    attributed as more informative (lower values on chart_intent) than
    persuasive (higher values on chart_intent)

Further, model comparisons indicate that MODEL 4 (adding a simple main
effect of `MAKER_DATA`) is a significantly better fit to the data than
MODEL 3 without the `MAKER_DATA` fixed effect
($\chi^2(1)=89.1 , p < 0.001$) .

**Model 4 supports our claim that social attributions (in this case,
*both* an inference about the communicative intent of the chart and
inference about the data analysis skill of the maker) *also* predict
beauty, and in fact can change (in the case of intent, moderate) the
effect of beauty on trust.**

#### (FIG 9) Predicting Trust

**Here we produce the visualization and model parameters table reported
in Figure 9.**

```{r best-fit-model}

################## PLOT MODEL
p + plot_annotation(title = f.BxID, caption="low intent = inform, high intent = persuade; low data = professional, high data = layperson", subtitle = f.BxID)

################## PRINT MODEL
tab_model(mm.BxID)

```

# ADDITIONAL BLOCKS

**In addition to the descriptive analysis of stimuli in Block 2 that is
reported in the manuscript, here we create visualize the semantic
differential scale for *each* stimulus in Study 2.**

## SD questions for each stimulus

```{r plot_halfeye_sdsplot_ALL, warning=FALSE}


#DEFINE STIMULI
df <- df_graphs
stimuli <- levels(df$STIMULUS)
graphs <- list()


## LOOP THROUGH EACH STIMULUS IN LIST
i = 0

for (s in stimuli){
  i = i+1
  
  # setup titles 
  title <- ref_stimuli %>% filter(ID == s) %>% select(NAME)  ##TODO IF NOT WORK ref_stim_id
  title <- paste(s,"|",title)

  # setup dataframe
  df <- df_sd_questions_long %>% select(1:8, STIMULUS, QUESTION, STIMULUS_CATEGORY, value) %>% filter(STIMULUS == s)
  d <- left_join( x = df, y = ref_labels, 
                  by = c("QUESTION" = "ref_sd_questions")) %>% 
        mutate(
               category=factor(category, levels=c("COMPETENCY","MAKER","CHART")),
          QUESTION = factor(QUESTION, levels=ref_sd_questions)) %>% 
    group_by(QUESTION) %>% 
    mutate(m=median(value)) ## calc median for printing on graph

  # GGDIST HALFEYE (raincloud doesn't work b/c long tails)
  (g <- d %>%
      ggplot(aes(y = fct_rev(QUESTION), x = value, fill=category)) +
    stat_halfeye(scale=0.8, density="bounded", point_interval = "median_qi", normalize="xy") +
    
    ## MEDIAN
    stat_summary(fun=median, geom="text", fontface = "bold", size= 2.2,
                vjust=+2, hjust = 0.50, aes(label=round(m, digits=0)))+
    stat_summary(fun=median, geom="point", size=2) +
    scale_color_manual(values = my_palettes(name="greys", direction = "1"))+
    scale_fill_manual(values = my_palettes(name="greys", direction = "1"))+
    guides(
      y = guide_axis_manual(labels = rev(ref_labels$left), title = ""),
      y.sec = guide_axis_manual(labels = rev(ref_labels$right))
    ) +
  cowplot::draw_text(text = ref_sd_questions, x = 90, y= ref_sd_questions,size = 8, vjust=-2) +
  labs (title = title, y = "", caption = "(point is median)") +
  theme_minimal() + easy_remove_legend()
)

  graphs[[i]] <- g
  
  if(GRAPH_SAVE == TRUE){ 
  ggsave(plot = g, path="figs/other_blocks/", filename =paste0(s,"_ggdist.png"), units = c("in"), width = 10, height = 14,  bg='#ffffff'  )}
  

  
  
} ## END LOOP 

graphs
```

# SESSION

```{r session}
sessionInfo()
```
